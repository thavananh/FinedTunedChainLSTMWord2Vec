Model Parameters:
learning_rate: 3.008192242169159e-05
batch_size: 128
dropout_features: 0.4
dropout_combine: 0.0
cnn_1_filter_size: 256
cnn_1_kernel_size: 7
cnn_1_padding: valid
cnn_1_activation: relu
cnn_1_dropout_rate: 0.30000000000000004
cnn_2_filter_size: 32
cnn_2_kernel_size: 3
cnn_2_padding: same
cnn_2_activation: relu
cnn_2_dropout_rate: 0.2
cnn_3_filter_size: 96
cnn_3_kernel_size: 5
cnn_3_padding: same
cnn_3_activation: tanh
cnn_3_dropout_rate: 0.4
cnn_4_filter_size: 128
cnn_4_kernel_size: 3
cnn_4_padding: same
cnn_4_activation: sigmoid
cnn_4_dropout_rate: 0.0
lstm_1_units: 512
lstm_1_dropout_rate: 0.1
lstm_2_units: 256
lstm_2_dropout_rate: 0.4
multi_head_attention_num_heads: 4
multi_head_attention_key_dim: 32
multi_head_attention_dropout_rate: 0.4
dense_1_units: 384
dense_1_dropout_rate: 0.1
dense_1_activation: elu
dense_2_units: 384
dense_2_dropout_rate: 0.0
dense_2_activation: silu
dense_3_units: 384
dense_3_dropout_rate: 0.30000000000000004
dense_3_activation: log_softmax

Word2Vec Parameters:
w2v_sg: 0
w2v_vector_size: 200
w2v_window: 3
w2v_min_count: 5
w2v_negative: 10
w2v_sample: 0.00020072768493455476
