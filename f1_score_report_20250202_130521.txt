Model Parameters:
learning_rate: 0.0003593909217355272
batch_size: 64
dropout_features: 0.30000000000000004
dropout_combine: 0.1
cnn_1_filter_size: 160
cnn_1_kernel_size: 7
cnn_1_padding: same
cnn_1_activation: gelu
cnn_1_dropout_rate: 0.0
cnn_2_filter_size: 32
cnn_2_kernel_size: 3
cnn_2_padding: same
cnn_2_activation: relu
cnn_2_dropout_rate: 0.4
cnn_3_filter_size: 160
cnn_3_kernel_size: 7
cnn_3_padding: valid
cnn_3_activation: silu
cnn_3_dropout_rate: 0.1
cnn_4_filter_size: 64
cnn_4_kernel_size: 7
cnn_4_padding: same
cnn_4_activation: gelu
cnn_4_dropout_rate: 0.0
lstm_1_units: 448
lstm_1_dropout_rate: 0.2
lstm_2_units: 320
lstm_2_dropout_rate: 0.1
multi_head_attention_num_heads: 8
multi_head_attention_key_dim: 128
multi_head_attention_dropout_rate: 0.4
dense_1_units: 256
dense_1_dropout_rate: 0.2
dense_1_activation: relu
dense_2_units: 192
dense_2_dropout_rate: 0.2
dense_2_activation: relu
dense_3_units: 320
dense_3_dropout_rate: 0.2
dense_3_activation: log_softmax

Word2Vec Parameters:
w2v_sg: 1
w2v_vector_size: 300
w2v_window: 7
w2v_min_count: 6
w2v_negative: 10
w2v_sample: 6.53844688159917e-05
