{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10173164,"sourceType":"datasetVersion","datasetId":6283249},{"sourceId":10421300,"sourceType":"datasetVersion","datasetId":6459110},{"sourceId":10421314,"sourceType":"datasetVersion","datasetId":6459120},{"sourceId":10435593,"sourceType":"datasetVersion","datasetId":6462286},{"sourceId":10458809,"sourceType":"datasetVersion","datasetId":6474728},{"sourceId":10461000,"sourceType":"datasetVersion","datasetId":6476343},{"sourceId":10490881,"sourceType":"datasetVersion","datasetId":6495600},{"sourceId":10507307,"sourceType":"datasetVersion","datasetId":6504918},{"sourceId":10605325,"sourceType":"datasetVersion","datasetId":6564932},{"sourceId":10606086,"sourceType":"datasetVersion","datasetId":6565412},{"sourceId":221689,"sourceType":"modelInstanceVersion","modelInstanceId":189088,"modelId":211095},{"sourceId":222665,"sourceType":"modelInstanceVersion","modelInstanceId":189952,"modelId":211948},{"sourceId":222668,"sourceType":"modelInstanceVersion","modelInstanceId":189955,"modelId":211951},{"sourceId":225237,"sourceType":"modelInstanceVersion","modelInstanceId":192126,"modelId":214070},{"sourceId":225548,"sourceType":"modelInstanceVersion","modelInstanceId":192388,"modelId":214326},{"sourceId":228809,"sourceType":"modelInstanceVersion","modelInstanceId":195110,"modelId":217007},{"sourceId":228851,"sourceType":"modelInstanceVersion","modelInstanceId":195144,"modelId":217042},{"sourceId":228858,"sourceType":"modelInstanceVersion","modelInstanceId":195150,"modelId":217048},{"sourceId":228881,"sourceType":"modelInstanceVersion","modelInstanceId":195168,"modelId":217067},{"sourceId":228885,"sourceType":"modelInstanceVersion","modelInstanceId":195171,"modelId":217070},{"sourceId":228896,"sourceType":"modelInstanceVersion","modelInstanceId":195181,"modelId":217080},{"sourceId":233355,"sourceType":"modelInstanceVersion","modelInstanceId":199228,"modelId":221051},{"sourceId":235376,"sourceType":"modelInstanceVersion","modelInstanceId":201048,"modelId":222858}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-29T03:48:53.309181Z","iopub.execute_input":"2025-01-29T03:48:53.309433Z","iopub.status.idle":"2025-01-29T03:48:53.708302Z","shell.execute_reply.started":"2025-01-29T03:48:53.309405Z","shell.execute_reply":"2025-01-29T03:48:53.707407Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/word2vec_v5/other/default/1/model_ug_cbow.word2vec\n/kaggle/input/word2vec_v5/other/default/1/model_ug_sg.word2vec\n/kaggle/input/uit-dataset/UIT-VSFC_dev.csv\n/kaggle/input/uit-dataset/UIT-VSFC_test.csv\n/kaggle/input/uit-dataset/UIT-VSFC_train.csv\n/kaggle/input/uit-vsfc-tao-sinh-balanced/UIT-VSFC_train_tao_sinh_balanced.csv\n/kaggle/input/word2vec_v4/other/default/1/model_ug_cbow.word2vec\n/kaggle/input/word2vec_v4/other/default/1/model_ug_sg.word2vec\n/kaggle/input/word2vec/other/default/1/word2vec_train_on_review_dataset.model\n/kaggle/input/word2vec_v11/other/default/1/model_ug_cbow.word2vec\n/kaggle/input/word2vec_v11/other/default/1/model_ug_sg.word2vec\n/kaggle/input/stopwords-small/stopwords-vi_news.txt\n/kaggle/input/stopwords-small-v3/stopwords-vi_news.txt\n/kaggle/input/word2vec_v2/other/default/1/word2vec_ug_sg.word2vec\n/kaggle/input/word2vec_v2/other/default/1/word2vec_ug_cbow.word2vec\n/kaggle/input/uit-vsfc-train-balance/UIT-VSFC_train_undersampling_10.csv\n/kaggle/input/uit-vsfc-train-balance/UIT-VSFC_train_oversampling_10.csv\n/kaggle/input/uit-vsfc-train-balance/UIT-VSFC_train_undersampling_20.csv\n/kaggle/input/uit-vsfc-train-balance/UIT-VSFC_train_undersampling_30.csv\n/kaggle/input/uit-vsfc-train-balance/UIT-VSFC_train_oversampling_20.csv\n/kaggle/input/uit-vsfc-train-balance/UIT-VSFC_train_oversampling_30.csv\n/kaggle/input/29012025-1/UIT-VSFC_train_cleaned_simple.csv\n/kaggle/input/29012025-1/model_sg.word2vec\n/kaggle/input/29012025-1/UIT-VSFC_dev_cleaned_simple.csv\n/kaggle/input/29012025-1/UIT-VSFC_test_cleaned_simple.csv\n/kaggle/input/29012025-1/model_cbow.word2vec\n/kaggle/input/word2vec_ug_sg/other/default/1/word2vec_ug_sg.word2vec\n/kaggle/input/stopwords-small-v2/stopwords-vi_news.txt\n/kaggle/input/word2vec_v3/other/default/1/word2vec_ug_sg.word2vec\n/kaggle/input/word2vec_v3/other/default/1/word2vec_ug_cbow.word2vec\n/kaggle/input/w2v_uit_vsfc_v2_data_cleaned/other/default/1/w2v_model_ug_cbow.word2vec\n/kaggle/input/w2v_uit_vsfc_v2_data_cleaned/other/default/1/w2v_model_ug_sg.word2vec\n/kaggle/input/w2v_uit_vsfc_v2_data_cleaned/other/default/1/w2v_model_ug_cbow_300.word2vec\n/kaggle/input/w2v_uit_vsfc_v2_data_cleaned/other/default/1/w2v_model_ug_sg_300.word2vec\n/kaggle/input/word2vec_ug_cbow/other/default/1/word2vec_ug_cbow.word2vec\n/kaggle/input/uit-vsfc-cleaned-v4/UIT-VSFC_dev_cleaned.csv\n/kaggle/input/uit-vsfc-cleaned-v4/UIT-VSFC_train_cleaned.csv\n/kaggle/input/uit-vsfc-cleaned-v4/UIT-VSFC_test_cleaned.csv\n/kaggle/input/vietnamese-stopwords/vietnamese-stopwords.csv\n/kaggle/input/word2vec_v6/other/default/1/model_ug_cbow.word2vec\n/kaggle/input/word2vec_v6/other/default/1/model_ug_sg.word2vec\n/kaggle/input/word2vec_v8/other/default/1/model_ug_cbow.word2vec\n/kaggle/input/word2vec_v8/other/default/1/model_ug_sg.word2vec\n/kaggle/input/word2vec_v7/other/default/1/model_ug_cbow.word2vec\n/kaggle/input/word2vec_v7/other/default/1/model_ug_sg.word2vec\n/kaggle/input/smaller_vietnamese_stopwords/other/default/1/stopwords-vi_news.txt\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install pyvi\n!pip install underthesea","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T03:48:53.710103Z","iopub.execute_input":"2025-01-29T03:48:53.710465Z","iopub.status.idle":"2025-01-29T03:49:14.067051Z","shell.execute_reply.started":"2025-01-29T03:48:53.710437Z","shell.execute_reply":"2025-01-29T03:49:14.066168Z"}},"outputs":[{"name":"stdout","text":"Collecting pyvi\n  Downloading pyvi-0.1.1-py2.py3-none-any.whl.metadata (2.5 kB)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from pyvi) (1.2.2)\nCollecting sklearn-crfsuite (from pyvi)\n  Downloading sklearn_crfsuite-0.5.0-py2.py3-none-any.whl.metadata (4.9 kB)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pyvi) (1.26.4)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pyvi) (1.14.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pyvi) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pyvi) (3.5.0)\nCollecting python-crfsuite>=0.9.7 (from sklearn-crfsuite->pyvi)\n  Downloading python_crfsuite-0.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\nRequirement already satisfied: tabulate>=0.4.2 in /opt/conda/lib/python3.10/site-packages (from sklearn-crfsuite->pyvi) (0.9.0)\nRequirement already satisfied: tqdm>=2.0 in /opt/conda/lib/python3.10/site-packages (from sklearn-crfsuite->pyvi) (4.66.4)\nDownloading pyvi-0.1.1-py2.py3-none-any.whl (8.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading sklearn_crfsuite-0.5.0-py2.py3-none-any.whl (10 kB)\nDownloading python_crfsuite-0.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: python-crfsuite, sklearn-crfsuite, pyvi\nSuccessfully installed python-crfsuite-0.9.11 pyvi-0.1.1 sklearn-crfsuite-0.5.0\nCollecting underthesea\n  Downloading underthesea-6.8.4-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: Click>=6.0 in /opt/conda/lib/python3.10/site-packages (from underthesea) (8.1.7)\nRequirement already satisfied: python-crfsuite>=0.9.6 in /opt/conda/lib/python3.10/site-packages (from underthesea) (0.9.11)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from underthesea) (3.2.4)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from underthesea) (4.66.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from underthesea) (2.32.3)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from underthesea) (1.4.2)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from underthesea) (1.2.2)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from underthesea) (6.0.2)\nCollecting underthesea-core==1.0.4 (from underthesea)\n  Downloading underthesea_core-1.0.4-cp310-cp310-manylinux2010_x86_64.whl.metadata (1.7 kB)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk->underthesea) (1.16.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->underthesea) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->underthesea) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->underthesea) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->underthesea) (2024.6.2)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->underthesea) (1.26.4)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->underthesea) (1.14.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->underthesea) (3.5.0)\nDownloading underthesea-6.8.4-py3-none-any.whl (20.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.9/20.9 MB\u001b[0m \u001b[31m80.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading underthesea_core-1.0.4-cp310-cp310-manylinux2010_x86_64.whl (657 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m657.8/657.8 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: underthesea-core, underthesea\nSuccessfully installed underthesea-6.8.4 underthesea-core-1.0.4\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport pickle\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.layers import Embedding, Dense, Dropout, Bidirectional, LSTM, GRU, Input, GlobalMaxPooling1D, LayerNormalization\nfrom tensorflow.keras.optimizers import Adam, SGD\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nimport keras\nfrom keras.layers import Dense\nimport tensorflow as tf\nimport tensorflow_hub as hub\nimport tf_keras\nfrom pyvi import ViTokenizer\nfrom pyvi import ViUtils","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T03:49:14.068676Z","iopub.execute_input":"2025-01-29T03:49:14.069078Z","iopub.status.idle":"2025-01-29T03:49:27.734181Z","shell.execute_reply.started":"2025-01-29T03:49:14.069037Z","shell.execute_reply":"2025-01-29T03:49:27.733101Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"train_data = pd.read_csv('/kaggle/input/29012025-1/UIT-VSFC_train_cleaned_simple.csv')\ndev_data = pd.read_csv('/kaggle/input/29012025-1/UIT-VSFC_dev_cleaned_simple.csv')\ntest_data = pd.read_csv('/kaggle/input/29012025-1/UIT-VSFC_test_cleaned_simple.csv')\ntrain_data_tao_sinh = pd.read_csv('/kaggle/input/uit-vsfc-tao-sinh-balanced/UIT-VSFC_train_tao_sinh_balanced.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T03:49:27.735467Z","iopub.execute_input":"2025-01-29T03:49:27.735998Z","iopub.status.idle":"2025-01-29T03:49:28.118323Z","shell.execute_reply.started":"2025-01-29T03:49:27.735967Z","shell.execute_reply":"2025-01-29T03:49:28.117361Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"train_data = train_data.dropna()\ntest_data = test_data.dropna()\ndev_data = dev_data.dropna()\ntrain_data_tao_sinh = train_data_tao_sinh.dropna()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T03:49:28.119675Z","iopub.execute_input":"2025-01-29T03:49:28.120374Z","iopub.status.idle":"2025-01-29T03:49:28.140729Z","shell.execute_reply.started":"2025-01-29T03:49:28.120328Z","shell.execute_reply":"2025-01-29T03:49:28.139812Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"train_data.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T03:49:28.141803Z","iopub.execute_input":"2025-01-29T03:49:28.142089Z","iopub.status.idle":"2025-01-29T03:49:28.168740Z","shell.execute_reply.started":"2025-01-29T03:49:28.142063Z","shell.execute_reply":"2025-01-29T03:49:28.167802Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 11422 entries, 0 to 11421\nData columns (total 3 columns):\n #   Column      Non-Null Count  Dtype  \n---  ------      --------------  -----  \n 0   sents       11422 non-null  object \n 1   sentiments  11422 non-null  float64\n 2   tokens      11422 non-null  object \ndtypes: float64(1), object(2)\nmemory usage: 267.8+ KB\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"train_data_tao_sinh.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T03:49:28.171249Z","iopub.execute_input":"2025-01-29T03:49:28.171520Z","iopub.status.idle":"2025-01-29T03:49:28.187408Z","shell.execute_reply.started":"2025-01-29T03:49:28.171493Z","shell.execute_reply":"2025-01-29T03:49:28.186544Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 52692 entries, 0 to 52691\nData columns (total 3 columns):\n #   Column      Non-Null Count  Dtype  \n---  ------      --------------  -----  \n 0   sents       52692 non-null  object \n 1   sentiments  52692 non-null  float64\n 2   tokens      52692 non-null  object \ndtypes: float64(1), object(2)\nmemory usage: 1.2+ MB\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"dev_data.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T03:49:28.188497Z","iopub.execute_input":"2025-01-29T03:49:28.188786Z","iopub.status.idle":"2025-01-29T03:49:28.199220Z","shell.execute_reply.started":"2025-01-29T03:49:28.188758Z","shell.execute_reply":"2025-01-29T03:49:28.198351Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1583 entries, 0 to 1582\nData columns (total 3 columns):\n #   Column      Non-Null Count  Dtype  \n---  ------      --------------  -----  \n 0   sents       1583 non-null   object \n 1   sentiments  1583 non-null   float64\n 2   tokens      1583 non-null   object \ndtypes: float64(1), object(2)\nmemory usage: 37.2+ KB\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"test_data.info()\ny_test_1d = test_data.drop(test_data.columns[[0]],axis=1)\ny_test_1d = y_test_1d.values.tolist()\ny_test_1d = np.array(y_test_1d).flatten()\nprint(y_test_1d)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T03:49:28.200237Z","iopub.execute_input":"2025-01-29T03:49:28.200465Z","iopub.status.idle":"2025-01-29T03:49:28.241039Z","shell.execute_reply.started":"2025-01-29T03:49:28.200440Z","shell.execute_reply":"2025-01-29T03:49:28.240170Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 3166 entries, 0 to 3165\nData columns (total 3 columns):\n #   Column      Non-Null Count  Dtype  \n---  ------      --------------  -----  \n 0   sents       3166 non-null   object \n 1   sentiments  3166 non-null   float64\n 2   tokens      3166 non-null   object \ndtypes: float64(1), object(2)\nmemory usage: 74.3+ KB\n['2.0' \"['nói', 'tiếng', 'anh', 'lưu loát']\" '2.0' ...\n \"['tiếp thu', 'chậm']\" '1.0'\n \"['có', 'học', 'ở', 'trung tâm', 'tiếng', 'anh', 'ở', 'ngoài', 'trường', 'thời lượng', 'hợp lý', 'không', 'nhiều', 'không', 'ít', 'khoảng', 'tiết', 'buổi']\"]\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"train_data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T03:49:28.242136Z","iopub.execute_input":"2025-01-29T03:49:28.242405Z","iopub.status.idle":"2025-01-29T03:49:28.256769Z","shell.execute_reply.started":"2025-01-29T03:49:28.242380Z","shell.execute_reply":"2025-01-29T03:49:28.256058Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"                                               sents  sentiments  \\\n0                           tài liệu tài liệu đầy đủ         2.0   \n1                       nhiệt tình giảng dạy gần gũi         2.0   \n2                      đi học đầy đủ điểm chuyên cần         0.0   \n3  chưa áp dụng công nghệ thông tin các thiết bị ...         0.0   \n4  giảng bài hay có nhiều bài tập ví dụ ngay trên...         2.0   \n\n                                              tokens  \n0                 ['tài liệu', 'tài liệu', 'đầy đủ']  \n1             ['nhiệt tình', 'giảng dạy', 'gần gũi']  \n2   ['đi', 'học', 'đầy đủ', 'điểm', 'chuyên', 'cần']  \n3  ['chưa', 'áp dụng', 'công nghệ thông tin', 'cá...  \n4  ['giảng', 'bài', 'hay', 'có', 'nhiều', 'bài tậ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sents</th>\n      <th>sentiments</th>\n      <th>tokens</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>tài liệu tài liệu đầy đủ</td>\n      <td>2.0</td>\n      <td>['tài liệu', 'tài liệu', 'đầy đủ']</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>nhiệt tình giảng dạy gần gũi</td>\n      <td>2.0</td>\n      <td>['nhiệt tình', 'giảng dạy', 'gần gũi']</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>đi học đầy đủ điểm chuyên cần</td>\n      <td>0.0</td>\n      <td>['đi', 'học', 'đầy đủ', 'điểm', 'chuyên', 'cần']</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>chưa áp dụng công nghệ thông tin các thiết bị ...</td>\n      <td>0.0</td>\n      <td>['chưa', 'áp dụng', 'công nghệ thông tin', 'cá...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>giảng bài hay có nhiều bài tập ví dụ ngay trên...</td>\n      <td>2.0</td>\n      <td>['giảng', 'bài', 'hay', 'có', 'nhiều', 'bài tậ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"train_data_tao_sinh.info()\ny_train_tao_sinh_1d = train_data_tao_sinh.drop(train_data_tao_sinh.columns[[0, 2]],axis=1)\ny_train_tao_sinh_1d = y_train_tao_sinh_1d.values.tolist()\ny_train_tao_sinh_1d = np.array(y_train_tao_sinh_1d).flatten()\nprint(y_train_tao_sinh_1d)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T03:49:28.257585Z","iopub.execute_input":"2025-01-29T03:49:28.257883Z","iopub.status.idle":"2025-01-29T03:49:28.301564Z","shell.execute_reply.started":"2025-01-29T03:49:28.257856Z","shell.execute_reply":"2025-01-29T03:49:28.300648Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 52692 entries, 0 to 52691\nData columns (total 3 columns):\n #   Column      Non-Null Count  Dtype  \n---  ------      --------------  -----  \n 0   sents       52692 non-null  object \n 1   sentiments  52692 non-null  float64\n 2   tokens      52692 non-null  object \ndtypes: float64(1), object(2)\nmemory usage: 1.2+ MB\n[2. 0. 1. ... 0. 1. 1.]\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"train_data.info()\ny_train_1d = train_data.drop(train_data.columns[[0]],axis=1)\ny_train_1d = y_train_1d.values.tolist()\ny_train_1d = np.array(y_train_1d).flatten()\nprint(y_train_1d)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T03:49:28.302763Z","iopub.execute_input":"2025-01-29T03:49:28.303030Z","iopub.status.idle":"2025-01-29T03:49:28.435324Z","shell.execute_reply.started":"2025-01-29T03:49:28.303003Z","shell.execute_reply":"2025-01-29T03:49:28.434413Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 11422 entries, 0 to 11421\nData columns (total 3 columns):\n #   Column      Non-Null Count  Dtype  \n---  ------      --------------  -----  \n 0   sents       11422 non-null  object \n 1   sentiments  11422 non-null  float64\n 2   tokens      11422 non-null  object \ndtypes: float64(1), object(2)\nmemory usage: 267.8+ KB\n['2.0' \"['tài liệu', 'tài liệu', 'đầy đủ']\" '2.0' ...\n \"['dạy', 'dễ', 'hiểu', 'nhiệt tình']\" '2.0'\n \"['gói', 'gọn', 'hay', 'tận tình', 'phù hợp', 'mọi', 'trình độ', 'cũng', 'nhu cầu', 'môn học']\"]\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"import numpy as np\n\n# Kết hợp dữ liệu\n# data_full = pd.concat([train_data, dev_data, test_data], ignore_index=True)\n\n# Tự động chuyển giá trị không hợp lệ thành NaN\ntrain_data.iloc[:, 1] = pd.to_numeric(train_data.iloc[:, 1], errors='coerce')\n\n# Loại bỏ các hàng chứa NaN trong cả data_full\ntrain_data = train_data.dropna(subset=[train_data.columns[1]])\n\n# Chuyển cột cuối cùng thành kiểu số nguyên và mảng 1 chiều\nlabel_idx_train = train_data.iloc[:, 1].astype(int).to_numpy()\n\nprint(label_idx_train)\n\n# Chuyển đổi nhãn thành định dạng one-hot encoding\nlabel_tf_train = tf_keras.utils.to_categorical(label_idx_train, num_classes=3, dtype='float32')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T03:49:28.436381Z","iopub.execute_input":"2025-01-29T03:49:28.436675Z","iopub.status.idle":"2025-01-29T03:49:28.446840Z","shell.execute_reply.started":"2025-01-29T03:49:28.436641Z","shell.execute_reply":"2025-01-29T03:49:28.445946Z"}},"outputs":[{"name":"stdout","text":"[2 2 0 ... 0 2 2]\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"import numpy as np\n\n# Kết hợp dữ liệu\n# data_full = pd.concat([train_data, dev_data, test_data], ignore_index=True)\n\n# Tự động chuyển giá trị không hợp lệ thành NaN\ntrain_data_tao_sinh.iloc[:, 1] = pd.to_numeric(train_data_tao_sinh.iloc[:, 1], errors='coerce')\n\n# Loại bỏ các hàng chứa NaN trong cả data_full\ntrain_data_tao_sinh = train_data_tao_sinh.dropna(subset=[train_data_tao_sinh.columns[1]])\n\n# Chuyển cột cuối cùng thành kiểu số nguyên và mảng 1 chiều\nlabel_idx_train_tao_sinh = train_data_tao_sinh.iloc[:, 1].astype(int).to_numpy()\n\nprint(label_idx_train_tao_sinh)\n\n# Chuyển đổi nhãn thành định dạng one-hot encoding\nlabel_tf_train_tao_sinh = tf_keras.utils.to_categorical(label_idx_train_tao_sinh, num_classes=3, dtype='float32')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T03:49:28.447877Z","iopub.execute_input":"2025-01-29T03:49:28.448246Z","iopub.status.idle":"2025-01-29T03:49:28.464653Z","shell.execute_reply.started":"2025-01-29T03:49:28.448201Z","shell.execute_reply":"2025-01-29T03:49:28.463671Z"}},"outputs":[{"name":"stdout","text":"[2 0 1 ... 0 1 1]\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"import numpy as np\n\n# Kết hợp dữ liệu\n# data_full = pd.concat([train_data, dev_data, test_data], ignore_index=True)\n\n# Tự động chuyển giá trị không hợp lệ thành NaN\ntest_data.iloc[:, 1] = pd.to_numeric(test_data.iloc[:, 1], errors='coerce')\n\n# Loại bỏ các hàng chứa NaN trong cả data_full\ntest_data = test_data.dropna(subset=[test_data.columns[1]])\n\n# Chuyển cột cuối cùng thành kiểu số nguyên và mảng 1 chiều\nlabel_idx_test = test_data.iloc[:, 1].astype(int).to_numpy()\n\nprint(label_idx_test)\n\n# Chuyển đổi nhãn thành định dạng one-hot encoding\nlabel_tf_test = tf_keras.utils.to_categorical(label_idx_test, num_classes=3, dtype='float32')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T03:49:28.466008Z","iopub.execute_input":"2025-01-29T03:49:28.466368Z","iopub.status.idle":"2025-01-29T03:49:28.476262Z","shell.execute_reply.started":"2025-01-29T03:49:28.466328Z","shell.execute_reply":"2025-01-29T03:49:28.475406Z"}},"outputs":[{"name":"stdout","text":"[2 2 2 ... 2 0 1]\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"import numpy as np\n\n# Kết hợp dữ liệu\n# data_full = pd.concat([train_data, dev_data, test_data], ignore_index=True)\n\n# Tự động chuyển giá trị không hợp lệ thành NaN\ndev_data.iloc[:, 1] = pd.to_numeric(dev_data.iloc[:, 1], errors='coerce')\n\n# Loại bỏ các hàng chứa NaN trong cả data_full\ndev_data = dev_data.dropna(subset=[dev_data.columns[1]])\n\n# Chuyển cột cuối cùng thành kiểu số nguyên và mảng 1 chiều\nlabel_idx_dev = dev_data.iloc[:, 1].astype(int).to_numpy()\n\nprint(label_idx_dev)\n\n# Chuyển đổi nhãn thành định dạng one-hot encoding\nlabel_tf_dev = tf_keras.utils.to_categorical(label_idx_dev, num_classes=3, dtype='float32')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T03:49:28.477488Z","iopub.execute_input":"2025-01-29T03:49:28.477950Z","iopub.status.idle":"2025-01-29T03:49:28.491854Z","shell.execute_reply.started":"2025-01-29T03:49:28.477887Z","shell.execute_reply":"2025-01-29T03:49:28.490971Z"}},"outputs":[{"name":"stdout","text":"[0 0 2 ... 0 0 0]\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"print(dev_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T03:49:28.492937Z","iopub.execute_input":"2025-01-29T03:49:28.493271Z","iopub.status.idle":"2025-01-29T03:49:28.507763Z","shell.execute_reply.started":"2025-01-29T03:49:28.493234Z","shell.execute_reply":"2025-01-29T03:49:28.506826Z"}},"outputs":[{"name":"stdout","text":"                                                  sents  sentiments  \\\n0                                  tài liệu chưa cụ thể         0.0   \n1                                        giảng buồn ngủ         0.0   \n2                                      vui tính tận tâm         2.0   \n3     nên giao bài tập nhiều hơn chia nhóm làm bài t...         0.0   \n4     cần giảng bài chi tiết hơn đi sâu hơn chạy thử...         0.0   \n...                                                 ...         ...   \n1578                                hướng dẫn lab mơ hồ         0.0   \n1579  những bài tập mang tính thực hành thực tiễn ca...         2.0   \n1580                không dạy nhiều chủ yếu tự tìm hiểu         0.0   \n1581  muốn đổi tên môn học tên môn lập trình học thi...         0.0   \n1582  vừa dạy vừa trò chuyện hoặc gọi điện thoại thư...         0.0   \n\n                                                 tokens  \n0                        ['tài liệu', 'chưa', 'cụ thể']  \n1                              ['giảng', 'buồn', 'ngủ']  \n2                            ['vui', 'tính', 'tận tâm']  \n3     ['nên', 'giao', 'bài tập', 'nhiều', 'hơn', 'ch...  \n4     ['cần', 'giảng', 'bài', 'chi tiết', 'hơn', 'đi...  \n...                                                 ...  \n1578                      ['hướng dẫn', 'lab', 'mơ hồ']  \n1579  ['những', 'bài tập', 'mang', 'tính', 'thực hàn...  \n1580  ['không', 'dạy', 'nhiều', 'chủ yếu', 'tự', 'tì...  \n1581  ['muốn', 'đổi', 'tên', 'môn học', 'tên', 'môn'...  \n1582  ['vừa', 'dạy', 'vừa', 'trò chuyện', 'hoặc', 'g...  \n\n[1583 rows x 3 columns]\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"y_train = label_tf_train\ny_dev = label_tf_dev\ny_test = label_tf_test\ny_train_tao_sinh = label_tf_train_tao_sinh\n\nprint(\"y_train shape:\", y_train.shape)\nprint(\"y_train_tao_sinh shape:\", y_train_tao_sinh.shape)\nprint(\"y_val shape:\", y_dev.shape)\nprint(\"y_test shape:\", y_test.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T03:49:28.508787Z","iopub.execute_input":"2025-01-29T03:49:28.509073Z","iopub.status.idle":"2025-01-29T03:49:28.520538Z","shell.execute_reply.started":"2025-01-29T03:49:28.509045Z","shell.execute_reply":"2025-01-29T03:49:28.519686Z"}},"outputs":[{"name":"stdout","text":"y_train shape: (11422, 3)\ny_train_tao_sinh shape: (52692, 3)\ny_val shape: (1583, 3)\ny_test shape: (3166, 3)\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"train_data_text = train_data.sents\ntest_data_text = test_data.sents\ndev_data_text = dev_data.sents\ntrain_data_text_tao_sinh = train_data_tao_sinh.sents","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T03:49:28.521739Z","iopub.execute_input":"2025-01-29T03:49:28.522357Z","iopub.status.idle":"2025-01-29T03:49:28.531886Z","shell.execute_reply.started":"2025-01-29T03:49:28.522313Z","shell.execute_reply":"2025-01-29T03:49:28.531178Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"train_data_text = train_data_text.values.tolist()\ntest_data_text = test_data_text.values.tolist()\ndev_data_text = dev_data_text.values.tolist()\ntrain_data_text_tao_sinh = train_data_text_tao_sinh.values.tolist()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T03:49:28.532821Z","iopub.execute_input":"2025-01-29T03:49:28.533075Z","iopub.status.idle":"2025-01-29T03:49:28.543314Z","shell.execute_reply.started":"2025-01-29T03:49:28.533050Z","shell.execute_reply":"2025-01-29T03:49:28.542560Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"import numpy as np\nimport ast  # Để chuyển đổi chuỗi về danh sách Python\n\n# Chuyển đổi từ chuỗi danh sách (nếu cần)\ntrain_data_tokens = train_data.tokens.apply(ast.literal_eval)\ntest_data_tokens = test_data.tokens.apply(ast.literal_eval)\ndev_data_tokens = dev_data.tokens.apply(ast.literal_eval)\n\n# Biến đổi về danh sách phẳng\ntrain_data_tokens = [token for sublist in train_data_tokens for token in sublist]\ntest_data_tokens = [token for sublist in test_data_tokens for token in sublist]\ndev_data_tokens = [token for sublist in dev_data_tokens for token in sublist]\n\n# Chuyển đổi thành NumPy array nếu cần\ntrain_data_tokens = np.array(train_data_tokens)\ntest_data_tokens = np.array(test_data_tokens)\ndev_data_tokens = np.array(dev_data_tokens)\n\n# In ra để kiểm tra\nprint(dev_data_tokens)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T03:49:28.544082Z","iopub.execute_input":"2025-01-29T03:49:28.544303Z","iopub.status.idle":"2025-01-29T03:49:28.896479Z","shell.execute_reply.started":"2025-01-29T03:49:28.544279Z","shell.execute_reply":"2025-01-29T03:49:28.895574Z"}},"outputs":[{"name":"stdout","text":"['tài liệu' 'chưa' 'cụ thể' ... 'gọi' 'điện thoại' 'thường xuyên']\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"print(train_data_tokens)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T03:49:28.902268Z","iopub.execute_input":"2025-01-29T03:49:28.902532Z","iopub.status.idle":"2025-01-29T03:49:28.907080Z","shell.execute_reply.started":"2025-01-29T03:49:28.902506Z","shell.execute_reply":"2025-01-29T03:49:28.906101Z"}},"outputs":[{"name":"stdout","text":"['tài liệu' 'tài liệu' 'đầy đủ' ... 'cũng' 'nhu cầu' 'môn học']\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"print(\"Sample train_data_tokens:\", train_data_tokens[:5])\nprint(\"Sample train_data_text:\", train_data_text[:5])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T03:49:28.908140Z","iopub.execute_input":"2025-01-29T03:49:28.908403Z","iopub.status.idle":"2025-01-29T03:49:28.920950Z","shell.execute_reply.started":"2025-01-29T03:49:28.908377Z","shell.execute_reply":"2025-01-29T03:49:28.920103Z"}},"outputs":[{"name":"stdout","text":"Sample train_data_tokens: ['tài liệu' 'tài liệu' 'đầy đủ' 'nhiệt tình' 'giảng dạy']\nSample train_data_text: ['tài liệu tài liệu đầy đủ', 'nhiệt tình giảng dạy gần gũi', 'đi học đầy đủ điểm chuyên cần', 'chưa áp dụng công nghệ thông tin các thiết bị hỗ trợ việc giảng dạy', 'giảng bài hay có nhiều bài tập ví dụ ngay trên lớp']\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":" pip install emot --upgrade","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T03:49:28.921926Z","iopub.execute_input":"2025-01-29T03:49:28.922169Z","iopub.status.idle":"2025-01-29T03:49:37.725191Z","shell.execute_reply.started":"2025-01-29T03:49:28.922145Z","shell.execute_reply":"2025-01-29T03:49:37.724197Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Collecting emot\n  Downloading emot-3.1-py3-none-any.whl.metadata (396 bytes)\nDownloading emot-3.1-py3-none-any.whl (61 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: emot\nSuccessfully installed emot-3.1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"stop here","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T03:49:37.726817Z","iopub.execute_input":"2025-01-29T03:49:37.727218Z","iopub.status.idle":"2025-01-29T03:49:37.734541Z","shell.execute_reply.started":"2025-01-29T03:49:37.727173Z","shell.execute_reply":"2025-01-29T03:49:37.732586Z"}},"outputs":[{"traceback":["\u001b[0;36m  Cell \u001b[0;32mIn[25], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    stop here\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"],"ename":"SyntaxError","evalue":"invalid syntax (4067800170.py, line 1)","output_type":"error"}],"execution_count":25},{"cell_type":"code","source":"# import string\n# import regex as re\n# import numpy as np\n# import pandas as pd\n# from underthesea import word_tokenize, text_normalize\n\n# # =======================\n# # Vietnamese Character Normalization Functions\n# # =======================\n\n# # Define Unicode and Unsigned Characters\n# uniChars = \"àáảãạâầấẩẫậăằắẳẵặèéẻẽẹêềếểễệđìíỉĩịòóỏõọôồốổỗộơờớởỡợùúủũụưừứửữựỳýỷỹỵÀÁẢÃẠÂẦẤẨẪẬĂẰẮẲẴẶÈÉẺẼẸÊỀẾỂỄỆĐÌÍỈĨỊÒÓỎÕỌÔỒỐỔỖỘƠỜỚỞỠỢÙÚỦŨỤƯỪỨỬỮỰỲÝỶỸỴÂĂĐÔƠƯ\"\n# unsignChars = \"aaaaaaaaaaaaaaaaaeeeeeeeeeeediiiiiooooooooooooooooouuuuuuuuuuuyyyyyAAAAAAAAAAAAAAAAAEEEEEEEEEEEDIIIOOOOOOOOOOOOOOOOOOOUUUUUUUUUUUYYYYYAADOOU\"\n\n# def loaddicchar():\n#     \"\"\"\n#     Load a dictionary mapping accented Vietnamese characters to their base forms.\n#     \"\"\"\n#     dic = {}\n#     # Define the list of accented characters (1252 encoding)\n#     char1252 = 'à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|' \\\n#               'ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|' \\\n#               'ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|' \\\n#               'À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|' \\\n#               'È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|' \\\n#               'Ì|Í|Ỉ|Ĩ|Ị|' \\\n#               'Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|' \\\n#               'Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|' \\\n#               'Ỳ|Ý|Ỷ|Ỹ|Ỵ'.split('|')\n\n#     # Define the list of UTF-8 encoded characters\n#     charutf8 = \"à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|\" \\\n#               \"ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|\" \\\n#               \"ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|\" \\\n#               \"À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|\" \\\n#               \"È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|\" \\\n#               \"Ì|Í|Ỉ|Ĩ|Ị|\" \\\n#               \"Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|\" \\\n#               \"Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|\" \\\n#               \"Ỳ|Ý|Ỷ|Ỹ|Ỵ\".split('|')\n\n#     # Create the dictionary mapping\n#     for i in range(len(char1252)):\n#         dic[char1252[i]] = charutf8[i]\n#     return dic\n\n# dicchar = loaddicchar()\n\n# def covert_unicode(txt):\n#     \"\"\"\n#     Convert accented Vietnamese characters to their base forms.\n#     \"\"\"\n#     return re.sub(\n#         r'à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|' \\\n#         r'è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|' \\\n#         r'ì|í|ỉ|ĩ|ị|' \\\n#         r'ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|' \\\n#         r'ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|' \\\n#         r'ỳ|ý|ỷ|ỹ|ỵ|' \\\n#         r'À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|' \\\n#         r'È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|' \\\n#         r'Ì|Í|Ỉ|Ĩ|Ị|' \\\n#         r'Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|' \\\n#         r'Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|' \\\n#         r'Ỳ|Ý|Ỷ|Ỹ|Ỵ',\n#         lambda x: dicchar[x.group()], txt)\n\n# # =======================\n# # Existing Vietnamese Accent Normalization Functions\n# # =======================\n\n# # Define mappings for Vietnamese vowels and their accents\n# # Note: Ensure that bang_nguyen_am and nguyen_am_to_ids are fully defined\n# bang_nguyen_am = [\n#     ['a', 'à', 'á', 'ả', 'ã', 'ạ'],\n#     ['ă', 'ằ', 'ắ', 'ẳ', 'ẵ', 'ặ'],\n#     ['â', 'ầ', 'ấ', 'ẩ', 'ẫ', 'ậ'],\n#     ['e', 'è', 'é', 'ẻ', 'ẽ', 'ẹ'],\n#     ['ê', 'ề', 'ế', 'ể', 'ễ', 'ệ'],\n#     ['i', 'ì', 'í', 'ỉ', 'ĩ', 'ị'],\n#     ['o', 'ò', 'ó', 'ỏ', 'õ', 'ọ'],\n#     ['ô', 'ồ', 'ố', 'ổ', 'ỗ', 'ộ'],\n#     ['ơ', 'ờ', 'ớ', 'ở', 'ỡ', 'ợ'],\n#     ['u', 'ù', 'ú', 'ủ', 'ũ', 'ụ'],\n#     ['ư', 'ừ', 'ứ', 'ử', 'ữ', 'ự'],\n#     ['y', 'ỳ', 'ý', 'ỷ', 'ỹ', 'ỵ'],\n#     # Add more vowels if necessary\n# ]\n\n# # Create a mapping from vowel to its indices in bang_nguyen_am\n# nguyen_am_to_ids = {}\n# for idx, vowel_group in enumerate(bang_nguyen_am):\n#     for jdx, vowel in enumerate(vowel_group):\n#         nguyen_am_to_ids[vowel] = (idx, jdx)\n\n# def is_valid_vietnam_word(word):\n#     chars = list(word)\n#     nguyen_am_index = -1\n#     for index, char in enumerate(chars):\n#         x, y = nguyen_am_to_ids.get(char, (-1, -1))\n#         if x != -1:\n#             if nguyen_am_index == -1:\n#                 nguyen_am_index = index\n#             else:\n#                 if index - nguyen_am_index != 1:\n#                     return False\n#                 nguyen_am_index = index\n#     return True\n\n# def chuan_hoa_dau_tieng_viet(word):\n#     if not is_valid_vietnam_word(word):\n#         return word\n#     chars = list(word)\n#     dau_cau = 0\n#     nguyen_am_index = []\n#     qu_or_gi = False\n#     for index, char in enumerate(chars):\n#         x, y = nguyen_am_to_ids.get(char, (-1, -1))\n#         if x == -1:\n#             continue\n#         elif x == 9:  # check qu\n#             if index != 0 and chars[index - 1] == 'q':\n#                 chars[index] = 'u'\n#                 qu_or_gi = True\n#         elif x == 5:  # check gi\n#             if index != 0 and chars[index - 1] == 'g':\n#                 chars[index] = 'i'\n#                 qu_or_gi = True\n#         if y != 0:\n#             dau_cau = y\n#             chars[index] = bang_nguyen_am[x][0]\n#             if not qu_or_gi or index != 1:\n#                 nguyen_am_index.append(index)\n#     if len(nguyen_am_index) < 2:\n#         if qu_or_gi:\n#             if len(chars) == 2:\n#                 x, y = nguyen_am_to_ids.get(chars[1], (-1, -1))\n#                 if x != -1:\n#                     chars[1] = bang_nguyen_am[x][dau_cau]\n#             else:\n#                 x, y = nguyen_am_to_ids.get(chars[2], (-1, -1))\n#                 if x != -1:\n#                     chars[2] = bang_nguyen_am[x][dau_cau]\n#                 else:\n#                     chars[1] = bang_nguyen_am[5][dau_cau] if chars[1] == 'i' else bang_nguyen_am[9][dau_cau]\n#             return ''.join(chars)\n#         return word\n#     for index in nguyen_am_index:\n#         x, y = nguyen_am_to_ids.get(chars[index], (-1, -1))\n#         if x == 4 or x == 8:  # Example indices for specific vowels like 'ê', 'ơ'\n#             chars[index] = bang_nguyen_am[x][dau_cau]\n#     if len(nguyen_am_index) == 2:\n#         if nguyen_am_index[-1] == len(chars) - 1:\n#             x, y = nguyen_am_to_ids.get(chars[nguyen_am_index[0]], (-1, -1))\n#             if x != -1:\n#                 chars[nguyen_am_index[0]] = bang_nguyen_am[x][dau_cau]\n#         else:\n#             x, y = nguyen_am_to_ids.get(chars[nguyen_am_index[1]], (-1, -1))\n#             if x != -1:\n#                 chars[nguyen_am_index[1]] = bang_nguyen_am[x][dau_cau]\n#     else:\n#         x, y = nguyen_am_to_ids.get(chars[nguyen_am_index[1]], (-1, -1))\n#         if x != -1:\n#             chars[nguyen_am_index[1]] = bang_nguyen_am[x][dau_cau]\n#     return ''.join(chars)\n\n# def chuan_hoa_dau_cau_tieng_viet(sentence):\n#     \"\"\"\n#     Normalize Vietnamese sentence to the old typing standard.\n#     :param sentence: str, input Vietnamese sentence\n#     :return: str, normalized sentence\n#     \"\"\"\n#     sentence = sentence.lower()\n#     words = sentence.split()\n#     for index, word in enumerate(words):\n#         # Using regex to handle punctuation around words\n#         cw = re.sub(r'(^\\p{P}*)([\\p{L}]+)(\\p{P}*$)', r'\\1/\\2/\\3', word).split('/')\n#         if len(cw) == 3:\n#             cw[1] = chuan_hoa_dau_tieng_viet(cw[1])\n#             words[index] = ''.join(cw)\n#     return ' '.join(words)\n\n# # =======================\n# # Additional Unicode Normalization Function\n# # =======================\n\n# # The covert_unicode function replaces accented characters with their base forms\n# # This can be used before or after the existing normalization depending on your needs\n\n# # =======================\n# # Existing Text Preprocessing Functions\n# # =======================\n\n# # Load stopwords from CSV\n# filename = '/kaggle/input/vietnamese-stopwords/vietnamese-stopwords.csv'\n# data = pd.read_csv(filename, names=['word'])\n# list_stopwords = data['word'].tolist()  # Convert to list for easier checking\n# myarray = np.asarray(list_stopwords)\n\n# # Load additional stopwords from text file\n# stopwords_small = []\n# with open('/kaggle/input/stopwords-small-v3/stopwords-vi_news.txt', 'r', encoding='utf-8') as file:\n#     stopwords_small = file.readlines()\n# list_rare_words_1 = [\n#         'fraction', 'altera', 'quad', 'cnpm', 'kaydotvn', 'daadotuitdotedudotvn', 'bohm', 'dotnet',\n#         'visual studio code', 'visual studio', 'visual code', 'visual', 'mutton quad', 'dreamweaver',\n#         'vertical fragmentation', 'i-ta-li-a', 'đbcl', 'crt', 'javabeans', 'if', 'for', 'while',\n#         'struct', 'pl', 'windows phone', 'pm', 'assembly', 'scrum_project', 'scrum project',\n#         'css', 'jquery', 'vector', 'gb', 'ram', 'ram', '...', 'codefun', 'egov', 'java', 'vmware',\n#         'placement', 'fork', 'round robin', 'patin', 'pattern', 'serverside', 'dotnet', 'c++',\n#         'javascript', 'ch', 'uit khoa', 'proteus', 'console', 'form', 'vật lý học', 'aep',\n#         'servlet', 'skype', 'doubledot', 'poster', 'everything', 'amp', 'app', 'seo', 'app',\n#         'progressive web', 'xim', 'win server', 'đối với', 'p', 's', 'p s', 'dropbox', 'bạn',\n#         'cplusplus', 'socket', 'sub', 'switch',\n#         'severside', 'network programing with csharp', 'dfd', 'naives bayes', 'naive', 'bayes', 'cs', 'js', 'max', 'elg', 'fix', 'proxy',\n#         'hub', 'bridge','switch', 'windows', 'turnitindotcom', 'extensive reading', 'reading', 'extensive', 'search', 'quick', 'file header','paper',\n#         'directx', 'windows', 'linux', 'vote', 'itdotf', 'router', 'silverlight', 'đa luồng', 'crack', 'wrede' ,'dbpedia','ontology', 'tmf', 'vhdl',\n#         'hdl', 'jsp', 'pđt', 'lisp', 'json', 'cpp', \n#     ]\n# # Clean stopwords list\n# stopwords_small = [line.strip().replace(\" \", \"_\") for line in stopwords_small]\n# stopwords_small.append('dot')\n# stopwords_small.append('giảng_viên')\n# for item in list_rare_words_1:\n#     stopwords_small.append(item)\n\n\n\n# def preprocess_text_vietnamese_to_text(text):\n#     \"\"\"\n#     Preprocess Vietnamese text by normalizing accents, removing unwanted elements,\n#     and tokenizing.\n#     :param text: str, input Vietnamese text\n#     :return: str, processed text\n#     \"\"\"\n#     # 0. Normalize Unicode accents (remove diacritics)\n#     text = covert_unicode(text)\n\n#     # 1. Normalize Vietnamese accents using existing functions\n#     text = chuan_hoa_dau_cau_tieng_viet(text)\n\n#     # 2. Chuyển đổi văn bản thành chữ thường\n#     text = text.lower()\n\n#     # 3. Thực hiện ánh xạ các cụm từ theo từ điển\n#     mapping_dict = {\n#         \"thầy giáo\": \"giảng viên\",\n#         \"cô giáo\": \"giảng viên\",\n#         \"thầy\": \"giảng viên\",\n#         \"cô\": \"giảng viên\",\n#         \"giáo viên\": \"giảng viên\",\n#         'vói': 'với',\n#         'giời': 'giờ',\n#         'nhiệt hình': 'nhiệt tình',\n#         'slides': 'slide',\n#         'side': 'slide',\n#         'tân tình': 'tận tình',\n#         'teacher': 'giảng viên',\n#         'sadcolon': 'colonsad',\n#         'vi dụ': 'ví dụ',\n#         'easy': 'dễ',\n#         'so vời': 'so với',\n#         'tâp': 'tập',\n#         'av': 'anh văn',\n#         'nhannh': 'nhanh',\n#         'h': 'giờ',\n#         'đc': 'được',\n#         'dc': 'được'\n#         # Thêm các cặp ánh xạ khác nếu cần\n#     }\n#     for original, replacement in mapping_dict.items():\n#         # Sử dụng regex để đảm bảo chỉ thay thế các cụm từ chính xác\n#         pattern = r'\\b' + re.escape(original) + r'\\b'\n#         text = re.sub(pattern, replacement, text)\n\n#     # 4. Loại bỏ dấu câu\n#     text = text.translate(str.maketrans('', '', string.punctuation))\n\n#     # 5. Loại bỏ số\n#     text = re.sub(r'\\d+', '', text)\n\n#     # 6. Loại bỏ khoảng trắng thừa ở đầu và cuối\n#     text = text.strip()\n\n#     # 7. Chuẩn hóa văn bản\n#     text = text_normalize(text)\n\n#     # 8. Loại bỏ biểu tượng cảm xúc (emojis)\n#     emoji_pattern = re.compile(\n#         \"[\"\n#         \"\\U0001F600-\\U0001F64F\"  # emoticons\n#         \"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n#         \"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n#         \"\\U0001F1E0-\\U0001F1FF\"  # flags\n#         \"\\U00002500-\\U00002BEF\"  # Chinese characters\n#         \"\\U00002702-\\U000027B0\"\n#         \"\\U00002702-\\U000027B0\"\n#         \"\\U000024C2-\\U0001F251\"\n#         \"\\U0001f926-\\U0001f937\"\n#         \"\\U00010000-\\U0010ffff\"\n#         \"\\u2640-\\u2642\"\n#         \"\\u2600-\\u2B55\"\n#         \"\\u200d\"\n#         \"\\u23cf\"\n#         \"\\u23e9\"\n#         \"\\u231a\"\n#         \"\\ufe0f\"  # dingbats\n#         \"\\u3030\"\n#         \"]+\",\n#         flags=re.UNICODE\n#     )\n#     text = emoji_pattern.sub(r'', text)\n\n#     # 9. Loại bỏ các tiền tố cụ thể nhưng giữ lại hậu tố\n#     text = re.sub(r'\\bcolon(\\w+)\\b', r'\\1', text)  # Loại bỏ tiền tố \"colon\" nhưng giữ lại hậu tố\n#     text = re.sub(r'\\bdoubledot(\\w+)\\b', r'\\1', text)  # Loại bỏ tiền tố \"doubledot\" nhưng giữ lại hậu tố\n\n#     # 10. Định nghĩa các tiền tố cần loại bỏ\n#     prefixes_to_remove = ['wzjwz', 'wwzjwz']\n\n#     # 11. Loại bỏ các từ bắt đầu bằng bất kỳ tiền tố nào trong danh sách\n#     for prefix in prefixes_to_remove:\n#         text = re.sub(r'\\b' + re.escape(prefix) + r'\\w*\\b', '', text)\n\n#     # 12. Loại bỏ các từ hiếm\n#     list_rare_words = [\n#         'fraction', 'altera', 'quad', 'cnpm', 'kaydotvn', 'daadotuitdotedudotvn', 'bohm', 'dotnet',\n#         'visual studio code', 'visual studio', 'visual code', 'visual', 'mutton quad', 'dreamweaver',\n#         'vertical fragmentation', 'i-ta-li-a', 'đbcl', 'crt', 'javabeans', 'if', 'for', 'while',\n#         'struct', 'pl', 'windows phone', 'pm', 'assembly', 'scrum_project', 'scrum project',\n#         'css', 'jquery', 'vector', 'gb', 'ram', 'ram', '...', 'codefun', 'egov', 'java', 'vmware',\n#         'placement', 'fork', 'round robin', 'patin', 'pattern', 'serverside', 'dotnet', 'c++',\n#         'javascript', 'ch', 'uit khoa', 'proteus', 'console', 'form', 'vật lý học', 'aep',\n#         'servlet', 'skype', 'doubledot', 'poster', 'everything', 'amp', 'app', 'seo', 'app',\n#         'progressive web', 'xim', 'win server', 'đối với', 'p', 's', 'p s', 'dropbox', 'bạn',\n#         'cplusplus', 'socket', 'sub', 'switch',\n#         'severside', 'network programing with csharp', 'dfd', 'naives bayes', 'naive', 'bayes', 'cs', 'js', 'max', 'elg', 'fix', 'proxy',\n#         'hub', 'bridge','switch', 'windows', 'turnitindotcom', 'extensive reading', 'reading', 'extensive', 'search', 'quick', 'file header','paper',\n#         'directx', 'windows', 'linux', 'vote', 'itdotf', 'router', 'silverlight', 'đa luồng', 'crack', 'wrede' ,'dbpedia','ontology', 'tmf', 'vhdl',\n#         'hdl', 'jsp', 'pđt', 'lisp', 'json', \n#     ]\n\n#     # Remove rare words using regex\n#     rarewords_pattern = r'\\b(?:' + '|'.join(re.escape(word) for word in list_rare_words) + r')\\b'\n#     text = re.sub(rarewords_pattern, '', text)\n\n#     # 13. Token hóa văn bản\n#     tokens = word_tokenize(text, format='text').split()\n#     tokens = [token for token in tokens if token not in stopwords_small]\n\n#     # 14. Loại bỏ các token rỗng nếu có\n#     tokens = [token for token in tokens if token.strip()]\n\n#     # 15. Ghép các token lại thành chuỗi văn bản đã xử lý\n#     processed_text = ' '.join(tokens)\n#     return processed_text\n\n\n# train_data_text = [preprocess_text_vietnamese_to_text(text) for text in train_data_text]\n# test_data_text = [preprocess_text_vietnamese_to_text(text) for text in test_data_text]\n# dev_data_text = [preprocess_text_vietnamese_to_text(text) for text in dev_data_text]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T03:49:37.736130Z","iopub.status.idle":"2025-01-29T03:49:37.736675Z","shell.execute_reply.started":"2025-01-29T03:49:37.736387Z","shell.execute_reply":"2025-01-29T03:49:37.736413Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(dev_data_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T03:49:37.738763Z","iopub.status.idle":"2025-01-29T03:49:37.739151Z","shell.execute_reply.started":"2025-01-29T03:49:37.738982Z","shell.execute_reply":"2025-01-29T03:49:37.739005Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"output_file = \"output.txt\"\nwith open(output_file, \"w\") as f:\n    # Chuyển từng phần tử thành chuỗi và thêm xuống dòng nếu chứa dấu ngoặc đóng\n    formatted_text = []\n    for item in train_data_text:\n        item_str = str(item)\n        if \")\" in item_str or \"]\" in item_str or \"}\" in item_str:\n            formatted_text.append(item_str + \"\\n\")  # Thêm xuống dòng\n        else:\n            formatted_text.append(item_str)\n    \n    # Kết hợp các phần tử lại và ghi vào file\n    f.write(\", \".join(formatted_text))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T03:49:37.740318Z","iopub.status.idle":"2025-01-29T03:49:37.740735Z","shell.execute_reply.started":"2025-01-29T03:49:37.740490Z","shell.execute_reply":"2025-01-29T03:49:37.740507Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import csv\n# Concatenate the lists\nall_data = train_data_text + test_data_text + dev_data_text\n\n# Define the output CSV file\ncsv_file = \"uit_vsfc_with_text_only.csv\"\n\n# Write the single column to the CSV file\nwith open(csv_file, mode='w', newline='', encoding='utf-8') as file:\n    writer = csv.writer(file)\n    # Write header\n    writer.writerow([\"Text\"])\n    # Write each item as a new row\n    for item in all_data:\n        writer.writerow([item])\n\nprint(f\"Data written to {csv_file}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T03:49:37.743004Z","iopub.status.idle":"2025-01-29T03:49:37.743458Z","shell.execute_reply.started":"2025-01-29T03:49:37.743222Z","shell.execute_reply":"2025-01-29T03:49:37.743246Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"length = []\nfor x in test_data_text:\n    length.append(len(x.split()))\nmax(length)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T03:49:37.744449Z","iopub.status.idle":"2025-01-29T03:49:37.744826Z","shell.execute_reply.started":"2025-01-29T03:49:37.744627Z","shell.execute_reply":"2025-01-29T03:49:37.744654Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_text_tokens_from_sent = [sent.split() for sent in train_data_text]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T03:55:02.484742Z","iopub.execute_input":"2025-01-29T03:55:02.485672Z","iopub.status.idle":"2025-01-29T03:55:02.518571Z","shell.execute_reply.started":"2025-01-29T03:55:02.485598Z","shell.execute_reply":"2025-01-29T03:55:02.517524Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"# print(train_text_tokens_from_sent)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T03:55:30.900075Z","iopub.execute_input":"2025-01-29T03:55:30.900786Z","iopub.status.idle":"2025-01-29T03:55:30.904497Z","shell.execute_reply.started":"2025-01-29T03:55:30.900753Z","shell.execute_reply":"2025-01-29T03:55:30.903497Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"tokenizer_data = Tokenizer()\ntokenizer_data.fit_on_texts(train_text_tokens_from_sent)\n\ntokenized_data_text_train = tokenizer_data.texts_to_sequences(train_data_text)\ntrain_features = pad_sequences(tokenized_data_text_train, maxlen=130)\n\ntokenized_data_text_test = tokenizer_data.texts_to_sequences(test_data_text)\ntest_features = pad_sequences(tokenized_data_text_test, maxlen=130)\n\ntokenized_data_text_dev = tokenizer_data.texts_to_sequences(dev_data_text)\ndev_features = pad_sequences(tokenized_data_text_dev, maxlen=130)\n\ntokenized_data_text_train_tao_sinh = tokenizer_data.texts_to_sequences(train_data_text_tao_sinh)\ntrain_features_tao_sinh = pad_sequences(tokenized_data_text_train_tao_sinh, maxlen=130)\n\npickle.dump(tokenizer_data, open(\"tokenizer_data.pkl\", \"wb\"))\ndata_vocab_size = len(tokenizer_data.word_index) + 1\n\nprint(\"input data shape:\", train_features.shape)\nprint(\"input data_tao_sinh shape:\",train_features_tao_sinh.shape)\nprint(\"data_vocab_size:\", data_vocab_size)\nprint(\"training sample:\", len(train_features))\nprint(\"validation sample:\", len(dev_features))\nprint(\"test sample:\", len(test_features))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T03:55:44.749091Z","iopub.execute_input":"2025-01-29T03:55:44.750023Z","iopub.status.idle":"2025-01-29T03:55:46.068503Z","shell.execute_reply.started":"2025-01-29T03:55:44.749973Z","shell.execute_reply":"2025-01-29T03:55:46.067534Z"}},"outputs":[{"name":"stdout","text":"input data shape: (11422, 130)\ninput data_tao_sinh shape: (52692, 130)\ndata_vocab_size: 1814\ntraining sample: 11422\nvalidation sample: 1583\ntest sample: 3166\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"tokenizer_data.word_index","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T03:55:48.368933Z","iopub.execute_input":"2025-01-29T03:55:48.369276Z","iopub.status.idle":"2025-01-29T03:55:48.392299Z","shell.execute_reply.started":"2025-01-29T03:55:48.369242Z","shell.execute_reply":"2025-01-29T03:55:48.391425Z"}},"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"{'dạy': 1,\n 'học': 2,\n 'bài': 3,\n 'tình': 4,\n 'không': 5,\n 'giảng': 6,\n 'có': 7,\n 'rất': 8,\n 'nhiệt': 9,\n 'hiểu': 10,\n 'nhiều': 11,\n 'tập': 12,\n 'dễ': 13,\n 'thực': 14,\n 'môn': 15,\n 'nên': 16,\n 'tâm': 17,\n 'thức': 18,\n 'được': 19,\n 'kiến': 20,\n 'hơn': 21,\n 'tận': 22,\n 'hay': 23,\n 'lớp': 24,\n 'hành': 25,\n 'cần': 26,\n 'trong': 27,\n 'làm': 28,\n 'các': 29,\n 'quá': 30,\n 'tốt': 31,\n 'khó': 32,\n 'tài': 33,\n 'liệu': 34,\n 'vui': 35,\n 'về': 36,\n 'chưa': 37,\n 'cách': 38,\n 'lý': 39,\n 'truyền': 40,\n 'những': 41,\n 'đạt': 42,\n 'giờ': 43,\n 'tính': 44,\n 'thể': 45,\n 'đề': 46,\n 'thời': 47,\n 'trình': 48,\n 'dẫn': 49,\n 'nói': 50,\n 'thuyết': 51,\n 'giải': 52,\n 'lên': 53,\n 'chỉ': 54,\n 'việc': 55,\n 'đến': 56,\n 'dụng': 57,\n 'kỹ': 58,\n 'gian': 59,\n 'hơi': 60,\n 'giúp': 61,\n 'hướng': 62,\n 'dung': 63,\n 'còn': 64,\n 'tiết': 65,\n 'thêm': 66,\n 'trên': 67,\n 'nội': 68,\n 'năng': 69,\n 'này': 70,\n 'tiếp': 71,\n 'phần': 72,\n 'quan': 73,\n 'bị': 74,\n 'đủ': 75,\n 'ra': 76,\n 'phòng': 77,\n 'cũng': 78,\n 'động': 79,\n 'điểm': 80,\n 'vào': 81,\n 'đi': 82,\n 'quả': 83,\n 'tạo': 84,\n 'sự': 85,\n 'rõ': 86,\n 'hợp': 87,\n 'thi': 88,\n 'khá': 89,\n 'án': 90,\n 'máy': 91,\n 'thu': 92,\n 'phải': 93,\n 'cấp': 94,\n 'đúng': 95,\n 'vẻ': 96,\n 'tế': 97,\n 'nhanh': 98,\n 'buổi': 99,\n 'hiệu': 100,\n 'kỳ': 101,\n 'đồ': 102,\n 'đầy': 103,\n 'pháp': 104,\n 'thường': 105,\n 'gì': 106,\n 'số': 107,\n 'thiết': 108,\n 'mới': 109,\n 'ví': 110,\n 'ít': 111,\n 'dụ': 112,\n 'lượng': 113,\n 'cao': 114,\n 'theo': 115,\n 'nghe': 116,\n 'phương': 117,\n 'công': 118,\n 'thông': 119,\n 'luôn': 120,\n 'báo': 121,\n 'đáp': 122,\n 'thiện': 123,\n 'cung': 124,\n 'cảm': 125,\n 'bảo': 126,\n 'nhà': 127,\n 'ý': 128,\n 'trường': 129,\n 'biết': 130,\n 'thấy': 131,\n 'vấn': 132,\n 'trước': 133,\n 'huyết': 134,\n 'chất': 135,\n 'tự': 136,\n 'tiếng': 137,\n 'hỏi': 138,\n 'mong': 139,\n 'nghỉ': 140,\n 'sau': 141,\n 'mắc': 142,\n 'sử': 143,\n 'liên': 144,\n 'chi': 145,\n 'từ': 146,\n 'khả': 147,\n 'hứng': 148,\n 'thắc': 149,\n 'đưa': 150,\n 'thân': 151,\n 'cụ': 152,\n 'khác': 153,\n 'ở': 154,\n 'gần': 155,\n 'nào': 156,\n 'nhóm': 157,\n 'đảm': 158,\n 'hài': 159,\n 'thú': 160,\n 'thích': 161,\n 'cả': 162,\n 'nhất': 163,\n 'anh': 164,\n 'sát': 165,\n 'điều': 166,\n 'xuyên': 167,\n 'lúc': 168,\n 'gây': 169,\n 'qua': 170,\n 'hình': 171,\n 'cập': 172,\n 'hệ': 173,\n 'người': 174,\n 'cuối': 175,\n 'trọng': 176,\n 'cơ': 177,\n 'nắm': 178,\n 'nâng': 179,\n 'đỡ': 180,\n 'tiễn': 181,\n 'chương': 182,\n 'câu': 183,\n 'đổi': 184,\n 'chuyên': 185,\n 'áp': 186,\n 'sâu': 187,\n 'tăng': 188,\n 'hoạt': 189,\n 'chán': 190,\n 'đầu': 191,\n 'ngoài': 192,\n 'ràng': 193,\n 'lòng': 194,\n 'tới': 195,\n 'bằng': 196,\n 'nữa': 197,\n 'nhật': 198,\n 'thay': 199,\n 'bản': 200,\n 'độ': 201,\n 'kết': 202,\n 'bắt': 203,\n 'phù': 204,\n 'hết': 205,\n 'nghĩ': 206,\n 'do': 207,\n 'cực': 208,\n 'đồng': 209,\n 'bổ': 210,\n 'mỗi': 211,\n 'tương': 212,\n 'trung': 213,\n 'yêu': 214,\n 'tìm': 215,\n 'tác': 216,\n 'chiếu': 217,\n 'ngủ': 218,\n 'ạ': 219,\n 'đôi': 220,\n 'cầu': 221,\n 'trễ': 222,\n 'đều': 223,\n 'lời': 224,\n 'thật': 225,\n 'ứng': 226,\n 'hiện': 227,\n 'sửa': 228,\n 'thương': 229,\n 'từng': 230,\n 'tích': 231,\n 'trợ': 232,\n 'thoải': 233,\n 'cái': 234,\n 'thống': 235,\n 'giữa': 236,\n 'mái': 237,\n 'chấm': 238,\n 'buồn': 239,\n 'chủ': 240,\n 'ôn': 241,\n 'nghiệm': 242,\n 'gũi': 243,\n 'phân': 244,\n 'vẫn': 245,\n 'tin': 246,\n 'ích': 247,\n 'tra': 248,\n 'kiểm': 249,\n 'chuẩn': 250,\n 'thiếu': 251,\n 'lực': 252,\n 'hỗ': 253,\n 'chậm': 254,\n 'kịp': 255,\n 'nhỏ': 256,\n 'đọc': 257,\n 'kinh': 258,\n 'hoặc': 259,\n 'chuyện': 260,\n 'rộng': 261,\n 'hút': 262,\n 'sinh': 263,\n 'trả': 264,\n 'hòa': 265,\n 'vừa': 266,\n 'lắm': 267,\n 'tham': 268,\n 'định': 269,\n 'thành': 270,\n 'đa': 271,\n 'thế': 272,\n 'toàn': 273,\n 'ngữ': 274,\n 'xem': 275,\n 'mở': 276,\n 'cùng': 277,\n 'lịch': 278,\n 'tuần': 279,\n 'phát': 280,\n 'mọi': 281,\n 'chú': 282,\n 'lập': 283,\n 'lần': 284,\n 'chia': 285,\n 'mạng': 286,\n 'tại': 287,\n 'mang': 288,\n 'hoàn': 289,\n 'bày': 290,\n 'bù': 291,\n 'đánh': 292,\n 'cải': 293,\n 'khóa': 294,\n 'chính': 295,\n 'giao': 296,\n 'dạng': 297,\n 'muốn': 298,\n 'luyện': 299,\n 'khăn': 300,\n 'giọng': 301,\n 'cáo': 302,\n 'chung': 303,\n 'phong': 304,\n 'dài': 305,\n 'ngành': 306,\n 'khiến': 307,\n 'khảo': 308,\n 'sai': 309,\n 'viết': 310,\n 'ơn': 311,\n 'giá': 312,\n 'nhìn': 313,\n 'nhàm': 314,\n 'nhận': 315,\n 'đang': 316,\n 'gặp': 317,\n 'nhau': 318,\n 'mất': 319,\n 'cố': 320,\n 'bộ': 321,\n 'thứ': 322,\n 'sắp': 323,\n 'ngày': 324,\n 'mục': 325,\n 'yếu': 326,\n 'bỏ': 327,\n 'ngồi': 328,\n 'khoa': 329,\n 'hiền': 330,\n 'nhiên': 331,\n 'danh': 332,\n 'xác': 333,\n 'xếp': 334,\n 'chỗ': 335,\n 'dùng': 336,\n 'nó': 337,\n 'lớn': 338,\n 'chứ': 339,\n 'minh': 340,\n 'năm': 341,\n 'vài': 342,\n 'nghiêm': 343,\n 'sao': 344,\n 'nghị': 345,\n 'đặc': 346,\n 'nộp': 347,\n 'chịu': 348,\n 'lab': 349,\n 'bên': 350,\n 'bọn': 351,\n 'hạn': 352,\n 'so': 353,\n 'đặt': 354,\n 'cường': 355,\n 'toán': 356,\n 'càng': 357,\n 'hước': 358,\n 'tuyệt': 359,\n 'bảng': 360,\n 'tất': 361,\n 'sở': 362,\n 'kiện': 363,\n 'chút': 364,\n 'chu': 365,\n 'đáo': 366,\n 'tư': 367,\n 'website': 368,\n 'vận': 369,\n 'biệt': 370,\n 'sớm': 371,\n 'nóng': 372,\n 'tránh': 373,\n 'vọng': 374,\n 'giảm': 375,\n 'kém': 376,\n 'bám': 377,\n 'smile': 378,\n 'lấy': 379,\n 'họa': 380,\n 'lỗi': 381,\n 'khí': 382,\n 'âm': 383,\n 'mềm': 384,\n 'nghiệp': 385,\n 'trao': 386,\n 'mặc': 387,\n 'xin': 388,\n 'cuốn': 389,\n 'cương': 390,\n 'sáng': 391,\n 'cũ': 392,\n 'tục': 393,\n 'trực': 394,\n 'nổi': 395,\n 'ngắn': 396,\n 'giác': 397,\n 'chép': 398,\n 'mặt': 399,\n 'xong': 400,\n 'lâu': 401,\n 'ngay': 402,\n 'deadline': 403,\n 'vị': 404,\n 'bao': 405,\n 'luận': 406,\n 'hội': 407,\n 'cận': 408,\n 'trò': 409,\n 'nặng': 410,\n 'nghệ': 411,\n 'sức': 412,\n 'ai': 413,\n 'tiến': 414,\n 'vô': 415,\n 'mờ': 416,\n 'seminar': 417,\n 'sung': 418,\n 'phục': 419,\n 'cứu': 420,\n 'chức': 421,\n 'lan': 422,\n 'việt': 423,\n 'nhớ': 424,\n 'mức': 425,\n 'giỏi': 426,\n 'kể': 427,\n 'quyết': 428,\n 'nghiên': 429,\n 'nhắc': 430,\n 'riêng': 431,\n 'tổ': 432,\n 'hầu': 433,\n 'mấy': 434,\n 'phút': 435,\n 'sôi': 436,\n 'mẫu': 437,\n 'dàng': 438,\n 'sơ': 439,\n 'vật': 440,\n 'khắc': 441,\n 'sẻ': 442,\n 'quạt': 443,\n 'man': 444,\n 'cứ': 445,\n 'vời': 446,\n 'ảnh': 447,\n 'xét': 448,\n 'thuật': 449,\n 'viên': 450,\n 'quy': 451,\n 'hy': 452,\n 'hai': 453,\n 'giới': 454,\n 'túc': 455,\n 'bận': 456,\n 'đào': 457,\n 'chế': 458,\n 'rèn': 459,\n 'micro': 460,\n 'chắc': 461,\n 'gọn': 462,\n 'song': 463,\n 'bất': 464,\n 'tiêu': 465,\n 'khoảng': 466,\n 'ngôn': 467,\n 'gia': 468,\n 'tụy': 469,\n 'gửi': 470,\n 'email': 471,\n 'sách': 472,\n 'thảo': 473,\n 'muộn': 474,\n 'sống': 475,\n 'thôi': 476,\n 'tốn': 477,\n 'đại': 478,\n 'loa': 479,\n 'ổn': 480,\n 'sẵn': 481,\n 'nghề': 482,\n 'tải': 483,\n 'thiệu': 484,\n 'biểu': 485,\n 'hồ': 486,\n 'điện': 487,\n 'diễn': 488,\n 'quản': 489,\n 'nhiệm': 490,\n 'dành': 491,\n 'trách': 492,\n 'khô': 493,\n 'hấp': 494,\n 'hi': 495,\n 'bớt': 496,\n 'vững': 497,\n 'mơ': 498,\n 'hữu': 499,\n 'chữ': 500,\n 'đơn': 501,\n 'thúc': 502,\n 'bố': 503,\n 'hư': 504,\n 'triển': 505,\n 'đối': 506,\n 'chơi': 507,\n 'tinh': 508,\n 'trùng': 509,\n 'chữa': 510,\n 'hưởng': 511,\n 'trạng': 512,\n 'đứng': 513,\n 'thái': 514,\n 'nhập': 515,\n 'nay': 516,\n 'giản': 517,\n 'đăng': 518,\n 'ghi': 519,\n 'cộng': 520,\n 'chạy': 521,\n 'tổng': 522,\n 'lắng': 523,\n 'sót': 524,\n 'gắng': 525,\n 'kéo': 526,\n 'cấu': 527,\n 'chỉnh': 528,\n 'giấc': 529,\n 'dữ': 530,\n 'bàn': 531,\n 'xúc': 532,\n 'game': 533,\n 'kế': 534,\n 'mô': 535,\n 'giống': 536,\n 'kiểu': 537,\n 'tượng': 538,\n 'trở': 539,\n 'vụ': 540,\n 'dõi': 541,\n 'thẳng': 542,\n 'đẹp': 543,\n 'lôi': 544,\n 'xa': 545,\n 'hôm': 546,\n 'chọn': 547,\n 'nghĩa': 548,\n 'cuộc': 549,\n 'đường': 550,\n 'vắng': 551,\n 'quát': 552,\n 'cứng': 553,\n 'lẫn': 554,\n 'góp': 555,\n 'phú': 556,\n 'kẽ': 557,\n 'đâu': 558,\n 'duy': 559,\n 'hỏng': 560,\n 'củng': 561,\n 'demo': 562,\n 'sàng': 563,\n 'nhân': 564,\n 'dưới': 565,\n 'sài': 566,\n 'chẳng': 567,\n 'buộc': 568,\n 'tưởng': 569,\n 'đích': 570,\n 'nền': 571,\n 'thanh': 572,\n 'kiếm': 573,\n 'nêu': 574,\n 'dịch': 575,\n 'up': 576,\n 'khan': 577,\n 'video': 578,\n 'bước': 579,\n 'rằng': 580,\n 'trẻ': 581,\n 'lạc': 582,\n 'linh': 583,\n 'thần': 584,\n 'bình': 585,\n 'doanh': 586,\n 'cạnh': 587,\n 'căn': 588,\n 'nguyên': 589,\n 'trúc': 590,\n 'sang': 591,\n 'quý': 592,\n 'đông': 593,\n 'nhu': 594,\n 'phí': 595,\n 'hề': 596,\n 'rớt': 597,\n 'mạch': 598,\n 'xuống': 599,\n 'nổ': 600,\n 'cá': 601,\n 'thụ': 602,\n 'lưỡng': 603,\n 'cài': 604,\n 'dòng': 605,\n 'đừng': 606,\n 'quên': 607,\n 'ồn': 608,\n 'nhờ': 609,\n 'phản': 610,\n 'tảng': 611,\n 'giấy': 612,\n 'cặn': 613,\n 'đem': 614,\n 'quen': 615,\n 'bụi': 616,\n 'tốc': 617,\n 'ngoại': 618,\n 'lưu': 619,\n 'chúc': 620,\n 'lẽ': 621,\n 'chuyển': 622,\n 'laptop': 623,\n 'tệ': 624,\n 'khích': 625,\n 'loại': 626,\n 'lai': 627,\n 'sợ': 628,\n 'hóa': 629,\n 'nản': 630,\n 'xuất': 631,\n 'cám': 632,\n 'đáng': 633,\n 'soạn': 634,\n 'cởi': 635,\n 'to': 636,\n 'nhẹ': 637,\n 'xây': 638,\n 'dựng': 639,\n 'chúng': 640,\n 'đời': 641,\n 'rối': 642,\n 'ký': 643,\n 'thưa': 644,\n 'nơi': 645,\n 'tối': 646,\n 'xử': 647,\n 'tín': 648,\n 'cười': 649,\n 'dặn': 650,\n 'chờ': 651,\n 'nhầm': 652,\n 'nửa': 653,\n 'chóng': 654,\n 'nhằm': 655,\n 'lặp': 656,\n 'khách': 657,\n 'rút': 658,\n 'khe': 659,\n 'lướt': 660,\n 'nối': 661,\n 'mạnh': 662,\n 'kèm': 663,\n 'đợi': 664,\n 'trừu': 665,\n 'suy': 666,\n 'ban': 667,\n 'giáo': 668,\n 'phức': 669,\n 'mệt': 670,\n 'lề': 671,\n 'khuyến': 672,\n 'sad': 673,\n 'đóng': 674,\n 'ân': 675,\n 'phụ': 676,\n 'tiện': 677,\n 'thuộc': 678,\n 'nhiêu': 679,\n 'trời': 680,\n 'gợi': 681,\n 'tên': 682,\n 'thao': 683,\n 'lợi': 684,\n 'lo': 685,\n 'nước': 686,\n 'ta': 687,\n 'chị': 688,\n 'wifi': 689,\n 'tiền': 690,\n 'hồi': 691,\n 'kênh': 692,\n 'cân': 693,\n 'đoạn': 694,\n 'cắm': 695,\n 'tháng': 696,\n 'ổ': 697,\n 'con': 698,\n 'trục': 699,\n 'trặc': 700,\n 'lạ': 701,\n 'hàng': 702,\n 'tỉ': 703,\n 'xảy': 704,\n 'chăm': 705,\n 'lố': 706,\n 'thử': 707,\n 'vựng': 708,\n 'chiều': 709,\n 'hoạch': 710,\n 'đột': 711,\n 'tiên': 712,\n 'khái': 713,\n 'trí': 714,\n 'tả': 715,\n 'phép': 716,\n 'coi': 717,\n 'lắp': 718,\n 'tắc': 719,\n 'tạp': 720,\n 'màn': 721,\n 'cửa': 722,\n 'phổ': 723,\n 'khỏe': 724,\n 'logic': 725,\n 'phấn': 726,\n 'thoại': 727,\n 'dồi': 728,\n 'hăng': 729,\n 'tay': 730,\n 'căng': 731,\n 'văn': 732,\n 'chứng': 733,\n 'xã': 734,\n 'biện': 735,\n 'trưa': 736,\n 'lĩnh': 737,\n 'nhở': 738,\n 'tầm': 739,\n 'ty': 740,\n 'tí': 741,\n 'kit': 742,\n 'nguồn': 743,\n 'chí': 744,\n 'khắt': 745,\n 'copy': 746,\n 'chả': 747,\n 'bó': 748,\n 'môi': 749,\n 'tóm': 750,\n 'trưởng': 751,\n 'xung': 752,\n 'kiên': 753,\n 'mời': 754,\n 'thoảng': 755,\n 'tân': 756,\n 'đòi': 757,\n 'che': 758,\n 'love': 759,\n 'kích': 760,\n 'mỏi': 761,\n 'trai': 762,\n 'hãy': 763,\n 'trắc': 764,\n 'ghế': 765,\n 'lộn': 766,\n 'mỉ': 767,\n 'gọi': 768,\n 'chê': 769,\n 'móc': 770,\n 'bức': 771,\n 'thuận': 772,\n 'nhàng': 773,\n 'trải': 774,\n 'trừ': 775,\n 'sắc': 776,\n 'huy': 777,\n 'biến': 778,\n 'khuôn': 779,\n 'lệ': 780,\n 'vực': 781,\n 'đàn': 782,\n 'xen': 783,\n 'nhộn': 784,\n 'báu': 785,\n 'kêu': 786,\n 'tranh': 787,\n 'lãng': 788,\n 'viện': 789,\n 'khối': 790,\n 'khai': 791,\n 'bữa': 792,\n 'tức': 793,\n 'họ': 794,\n 'di': 795,\n 'dựa': 796,\n 'phía': 797,\n 'chéo': 798,\n 'dãy': 799,\n 'thỉnh': 800,\n 'thí': 801,\n 'chiếm': 802,\n 'xíu': 803,\n 'suốt': 804,\n 'gắt': 805,\n 'suông': 806,\n 'ăn': 807,\n 'liền': 808,\n 'tòi': 809,\n 'nữ': 810,\n 'gắn': 811,\n 'xinh': 812,\n 'thấp': 813,\n 'rời': 814,\n 'may': 815,\n 'siêu': 816,\n 'trau': 817,\n 'tậm': 818,\n 'ha': 819,\n 'trì': 820,\n 'thù': 821,\n 'mẻ': 822,\n 'phỏng': 823,\n 'rèm': 824,\n 'chân': 825,\n 'chắn': 826,\n 'chém': 827,\n 'thủ': 828,\n 'vòng': 829,\n 'cử': 830,\n 'tử': 831,\n 'mê': 832,\n 'trị': 833,\n 'lựa': 834,\n 'ánh': 835,\n 'post': 836,\n 'chuột': 837,\n 'lệch': 838,\n 'y': 839,\n 'gò': 840,\n 'trầm': 841,\n 'sạch': 842,\n 'dường': 843,\n 'trống': 844,\n 'nề': 845,\n 'họp': 846,\n 'suất': 847,\n 'ham': 848,\n 'khổ': 849,\n 'cúp': 850,\n 'thậm': 851,\n 'khía': 852,\n 'gió': 853,\n 'niềm': 854,\n 'đam': 855,\n 'dần': 856,\n 'mày': 857,\n 'mò': 858,\n 'khung': 859,\n 'kính': 860,\n 'ào': 861,\n 'khuyên': 862,\n 'lành': 863,\n 'thất': 864,\n 'dự': 865,\n 'ghép': 866,\n 'hảo': 867,\n 'đặn': 868,\n 'lao': 869,\n 'rãi': 870,\n 'hằng': 871,\n 'dậy': 872,\n 'chật': 873,\n 'bóng': 874,\n 'quay': 875,\n 'quyền': 876,\n 'đẩy': 877,\n 'đậu': 878,\n 'phó': 879,\n 'súc': 880,\n 'sản': 881,\n 'phẩm': 882,\n 'vẽ': 883,\n 'ngược': 884,\n 'source': 885,\n 'nhấn': 886,\n 'diện': 887,\n 'nhúng': 888,\n 'say': 889,\n 'niệm': 890,\n 'đố': 891,\n 'h': 892,\n 'chừng': 893,\n 'biên': 894,\n 'truy': 895,\n 'hiếm': 896,\n 'hiễu': 897,\n 'đua': 898,\n 'sổ': 899,\n 'bối': 900,\n 'tùy': 901,\n 'tuân': 902,\n 'lạnh': 903,\n 'gián': 904,\n 'dám': 905,\n 'hái': 906,\n 'thang': 907,\n 'mến': 908,\n 'pha': 909,\n 'mát': 910,\n 'chênh': 911,\n 'loát': 912,\n 'dừng': 913,\n 'phiên': 914,\n 'dục': 915,\n 'nhạt': 916,\n 'đọng': 917,\n 'xấu': 918,\n 'bây': 919,\n 'tắt': 920,\n 'lung': 921,\n 'thư': 922,\n 'tràn': 923,\n 'bặm': 924,\n 'dây': 925,\n 'phim': 926,\n 'ơi': 927,\n 'ba': 928,\n 'nàn': 929,\n 'đương': 930,\n 'training': 931,\n 'lễ': 932,\n 'thiên': 933,\n 'rạc': 934,\n 'mắn': 935,\n 'nha': 936,\n 'nực': 937,\n 'xe': 938,\n 'ấn': 939,\n 'sánh': 940,\n 'thâm': 941,\n 'quốc': 942,\n 'giám': 943,\n 'hẳn': 944,\n 'phạt': 945,\n 'đứa': 946,\n 'khởi': 947,\n 'thừa': 948,\n 'đùa': 949,\n 'sĩ': 950,\n 'quanh': 951,\n 'am': 952,\n 'thô': 953,\n 'đươc': 954,\n 'khớp': 955,\n 'kê': 956,\n 'đau': 957,\n 'ngừng': 958,\n 'ngỡ': 959,\n 'bụng': 960,\n 'điển': 961,\n 'đuối': 962,\n 'thác': 963,\n 'giữ': 964,\n 'lơ': 965,\n 'surprise': 966,\n 'tán': 967,\n 'cẩn': 968,\n 'thận': 969,\n 'gộp': 970,\n 'êm': 971,\n 'quán': 972,\n 'nhẫn': 973,\n 'hời': 974,\n 'hợt': 975,\n 'hóc': 976,\n 'giơ': 977,\n 'lồng': 978,\n 'chang': 979,\n 'thuần': 980,\n 'thưởng': 981,\n 'thách': 982,\n 'chửi': 983,\n 'vai': 984,\n 'hoang': 985,\n 'phối': 986,\n 'dàn': 987,\n 'nhảm': 988,\n 'thắn': 989,\n 'vượt': 990,\n 'clip': 991,\n 'đành': 992,\n 'lối': 993,\n 'hủy': 994,\n 'hoài': 995,\n 'ước': 996,\n 'lau': 997,\n 'thắng': 998,\n 'chặt': 999,\n 'hụt': 1000,\n ...}"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"from gensim.models import Word2Vec\n\nfrom gensim.models import KeyedVectors\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T04:00:44.831914Z","iopub.execute_input":"2025-01-29T04:00:44.832565Z","iopub.status.idle":"2025-01-29T04:00:56.100640Z","shell.execute_reply.started":"2025-01-29T04:00:44.832529Z","shell.execute_reply":"2025-01-29T04:00:56.099955Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"# phow2v = KeyedVectors.load_word2vec_format('/kaggle/input/phow2v/other/default/1/word2vec_vi_words_300dims.txt', binary=False)\n# phow2v_syllables = KeyedVectors.load_word2vec_format('/kaggle/input/phow2v_syllables/other/default/1/word2vec_vi_syllables_300dims.txt', binary=False)\n# word2vec_cbow=Word2Vec.load('/kaggle/input/w2v_uit_vsfc_v2_data_cleaned/other/default/1/w2v_model_ug_cbow.word2vec')\n# word2vec_sg=Word2Vec.load('/kaggle/input/w2v_uit_vsfc_v2_data_cleaned/other/default/1/w2v_model_ug_sg.word2vec')\n\n# word2vec_cbow_300=Word2Vec.load('/kaggle/input/w2v_uit_vsfc_v2_data_cleaned/other/default/1/w2v_model_ug_cbow_300.word2vec')\n# word2vec_sg_300=Word2Vec.load('/kaggle/input/w2v_uit_vsfc_v2_data_cleaned/other/default/1/w2v_model_ug_sg_300.word2vec')\n\nword2vec_sg=Word2Vec.load('/kaggle/input/29012025-2/model_sg.word2vec')\nword2vec_cbow=Word2Vec.load('/kaggle/input/29012025-2/model_cbow.word2vec')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T04:01:35.016711Z","iopub.execute_input":"2025-01-29T04:01:35.017404Z","iopub.status.idle":"2025-01-29T04:01:35.043254Z","shell.execute_reply.started":"2025-01-29T04:01:35.017366Z","shell.execute_reply":"2025-01-29T04:01:35.042414Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"import numpy as np\n\nembeddings_index = {}\n\nfor w in word2vec_cbow.wv.key_to_index.keys():\n    \n    # embeddings_index[w] = np.append(word2vec_cbow.wv[w], word2vec_sg.wv[w])\n    embeddings_index[w] = word2vec_cbow.wv[w]\n\n\nprint('Found %s word vectors.' % len(embeddings_index))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T04:01:45.228989Z","iopub.execute_input":"2025-01-29T04:01:45.229850Z","iopub.status.idle":"2025-01-29T04:01:45.235713Z","shell.execute_reply.started":"2025-01-29T04:01:45.229815Z","shell.execute_reply":"2025-01-29T04:01:45.234862Z"}},"outputs":[{"name":"stdout","text":"Found 752 word vectors.\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"words = word2vec_cbow.wv.key_to_index.keys()\nprint(words)\nvocab_size = len(words)\nprint(\"Vocab size\", vocab_size)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T04:01:47.380061Z","iopub.execute_input":"2025-01-29T04:01:47.380399Z","iopub.status.idle":"2025-01-29T04:01:47.385542Z","shell.execute_reply.started":"2025-01-29T04:01:47.380365Z","shell.execute_reply":"2025-01-29T04:01:47.384680Z"}},"outputs":[{"name":"stdout","text":"dict_keys(['dạy', 'học', 'bài', 'tình', 'không', 'giảng', 'có', 'rất', 'nhiệt', 'hiểu', 'nhiều', 'tập', 'dễ', 'thực', 'môn', 'nên', 'tâm', 'thức', 'được', 'kiến', 'hơn', 'tận', 'hay', 'lớp', 'hành', 'cần', 'trong', 'làm', 'các', 'quá', 'tốt', 'khó', 'tài', 'liệu', 'vui', 'về', 'chưa', 'giờ', 'cách', 'lý', 'truyền', 'những', 'đạt', 'tính', 'thể', 'đề', 'thời', 'trình', 'dẫn', 'nói', 'thuyết', 'giải', 'lên', 'chỉ', 'việc', 'đến', 'dụng', 'kỹ', 'gian', 'hơi', 'giúp', 'hướng', 'dung', 'còn', 'tiết', 'thêm', 'nội', 'năng', 'trên', 'tiếp', 'này', 'phần', 'quan', 'bị', 'đủ', 'ra', 'phòng', 'cũng', 'động', 'điểm', 'vào', 'đi', 'quả', 'tạo', 'sự', 'rõ', 'hợp', 'thi', 'khá', 'án', 'máy', 'thu', 'phải', 'cấp', 'đúng', 'vẻ', 'nhanh', 'tế', 'buổi', 'hiệu', 'kỳ', 'đồ', 'pháp', 'đầy', 'thường', 'gì', 'số', 'thiết', 'mới', 'ít', 'ví', 'dụ', 'lượng', 'cao', 'theo', 'nghe', 'phương', 'công', 'thông', 'luôn', 'báo', 'đáp', 'thiện', 'cung', 'cảm', 'bảo', 'nhà', 'ý', 'trường', 'biết', 'thấy', 'vấn', 'huyết', 'trước', 'chất', 'tự', 'tiếng', 'hỏi', 'mong', 'nghỉ', 'sau', 'mắc', 'sử', 'liên', 'chi', 'từ', 'khả', 'hứng', 'thắc', 'thân', 'đưa', 'cụ', 'khác', 'ở', 'nào', 'gần', 'nhóm', 'đảm', 'hài', 'thú', 'thích', 'cả', 'nhất', 'anh', 'sát', 'điều', 'xuyên', 'gây', 'lúc', 'hình', 'cập', 'qua', 'hệ', 'người', 'cuối', 'cơ', 'trọng', 'nâng', 'tiễn', 'đỡ', 'nắm', 'chương', 'câu', 'đổi', 'chuyên', 'tăng', 'áp', 'sâu', 'hoạt', 'chán', 'đầu', 'ràng', 'ngoài', 'lòng', 'tới', 'bằng', 'nữa', 'nhật', 'thay', 'bản', 'bắt', 'kết', 'độ', 'phù', 'hết', 'nghĩ', 'do', 'cực', 'đồng', 'bổ', 'mỗi', 'tương', 'trung', 'tìm', 'yêu', 'tác', 'chiếu', 'ngủ', 'ạ', 'đôi', 'cầu', 'trễ', 'đều', 'lời', 'thật', 'hiện', 'ứng', 'từng', 'sửa', 'thương', 'tích', 'trợ', 'thoải', 'thống', 'cái', 'mái', 'buồn', 'chấm', 'giữa', 'chủ', 'ôn', 'nghiệm', 'phân', 'gũi', 'vẫn', 'tin', 'ích', 'tra', 'kiểm', 'chuẩn', 'thiếu', 'lực', 'chậm', 'hỗ', 'kịp', 'đọc', 'nhỏ', 'kinh', 'hoặc', 'chuyện', 'rộng', 'sinh', 'hút', 'hòa', 'vừa', 'trả', 'lắm', 'thành', 'tham', 'định', 'toàn', 'thế', 'đa', 'ngữ', 'tuần', 'xem', 'lịch', 'mở', 'cùng', 'phát', 'chú', 'mọi', 'lập', 'chia', 'lần', 'mang', 'tại', 'mạng', 'hoàn', 'bù', 'đánh', 'bày', 'cải', 'khóa', 'chính', 'giao', 'luyện', 'dạng', 'muốn', 'khăn', 'cáo', 'giọng', 'phong', 'chung', 'ngành', 'dài', 'sai', 'ơn', 'khiến', 'viết', 'khảo', 'giá', 'nhàm', 'nhìn', 'nhận', 'gặp', 'cố', 'đang', 'bộ', 'mất', 'nhau', 'thứ', 'ngày', 'sắp', 'mục', 'yếu', 'khoa', 'hiền', 'ngồi', 'bỏ', 'danh', 'nhiên', 'chỗ', 'xác', 'dùng', 'xếp', 'lớn', 'chứ', 'nó', 'minh', 'nghiêm', 'vài', 'sao', 'năm', 'so', 'bọn', 'nghị', 'chịu', 'hạn', 'đặc', 'bên', 'nộp', 'lab', 'hước', 'toán', 'cường', 'smile', 'càng', 'tuyệt', 'đặt', 'tư', 'chu', 'website', 'kiện', 'tất', 'sở', 'bảng', 'đáo', 'chút', 'vận', 'nóng', 'biệt', 'sớm', 'bám', 'vọng', 'kém', 'tránh', 'giảm', 'lấy', 'họa', 'nghiệp', 'khí', 'âm', 'lỗi', 'mềm', 'mặc', 'cuốn', 'cương', 'xin', 'sáng', 'cũ', 'trao', 'trực', 'tục', 'nổi', 'ngắn', 'lâu', 'xong', 'giác', 'chép', 'mặt', 'ngay', 'luận', 'bao', 'vị', 'deadline', 'nặng', 'hội', 'trò', 'cận', 'vô', 'tiến', 'sức', 'mờ', 'nghệ', 'ai', 'sung', 'seminar', 'phục', 'cứu', 'việt', 'lan', 'chức', 'giỏi', 'kể', 'nhớ', 'mức', 'quyết', 'tổ', 'riêng', 'nhắc', 'nghiên', 'sơ', 'phút', 'dàng', 'sôi', 'mấy', 'hầu', 'mẫu', 'quạt', 'cứ', 'vời', 'khắc', 'man', 'vật', 'sẻ', 'thuật', 'ảnh', 'viên', 'xét', 'đào', 'quy', 'rèn', 'hai', 'hy', 'chế', 'giới', 'bận', 'túc', 'microphone', 'email', 'gọn', 'chắc', 'bất', 'song', 'khoảng', 'tiêu', 'sách', 'ngôn', 'gửi', 'tụy', 'thảo', 'muộn', 'sống', 'gia', 'loa', 'ổn', 'thôi', 'đại', 'sẵn', 'tốn', 'nghề', 'thiệu', 'điện', 'biểu', 'dành', 'diễn', 'nhiệm', 'trách', 'tải', 'hồ', 'quản', 'hấp', 'vững', 'mơ', 'bớt', 'đơn', 'hữu', 'hi', 'thúc', 'chữ', 'khô', 'đối', 'chơi', 'trùng', 'tinh', 'hư', 'bố', 'triển', 'trạng', 'chạy', 'đứng', 'thái', 'tổng', 'cộng', 'đăng', 'chữa', 'nhập', 'nay', 'lắng', 'giản', 'hưởng', 'ghi', 'kéo', 'cấu', 'sót', 'giấc', 'bàn', 'game', 'dữ', 'xúc', 'chỉnh', 'gắng', 'vắng', 'dõi', 'mô', 'lôi', 'đường', 'nghĩa', 'chọn', 'thẳng', 'kế', 'xa', 'cuộc', 'hôm', 'đẹp', 'kiểu', 'tượng', 'vụ', 'trở', 'giống', 'lẫn', 'quát', 'duy', 'góp', 'củng', 'demo', 'sàng', 'cứng', 'hỏng', 'nhân', 'dưới', 'đâu', 'phú', 'kẽ', 'sài', 'chẳng', 'kiếm', 'dịch', 'buộc', 'nền', 'tưởng', 'đích', 'bước', 'thanh', 'nêu', 'thần', 'khan', 'bình', 'lạc', 'linh', 'doanh', 'video', 'rằng', 'trẻ', 'up', 'trúc', 'sang', 'quý', 'cạnh', 'nguyên', 'căn', 'lưỡng', 'cá', 'nhu', 'phí', 'thụ', 'cài', 'dòng', 'đừng', 'hề', 'xuống', 'nổ', 'đông', 'mạch', 'rớt', 'đem', 'lưu', 'ngoại', 'quên', 'phản', 'tốc', 'nhờ', 'cặn', 'tảng', 'ồn', 'giấy', 'bụi', 'quen', 'loại', 'cám', 'lai', 'laptop', 'khích', 'chuyển', 'tệ', 'lẽ', 'xuất', 'nản', 'chúc', 'đáng', 'sợ', 'hóa', 'nhẹ', 'cởi', 'c', 'nơi', 'chúng', 'ký', 'soạn', 'đời', 'tín', 'xây', 'rối', 'dựng', 'thưa', 'to', 'xử', 'tối', 'nhầm', 'lặp', 'chờ', 'nối', 'dặn', 'chóng', 'kèm', 'rút', 'nửa', 'nhằm', 'khe', 'mạnh', 'cười', 'khách', 'lướt', 'lợi', 'trời', 'ban', 'nhiêu', 'mệt', 'suy', 'lề', 'thuộc', 'gợi', 'trừu', 'ân', 'sad', 'giáo', 'tiện', 'phụ', 'lo', 'khuyến', 'tên', 'phức', 'đóng', 'thao', 'đợi', 'trặc', 'hàng', 'trục', 'chăm', 'hoạch', 'đột', 'cân', 'đoạn', 'wifi', 'thử', 'ổ', 'vựng', 'lố', 'lạ', 'cắm', 'chiều', 'con', 'tỉ', 'chị', 'kênh', 'tiền', 'ta', 'nước', 'hồi', 'xảy', 'tháng', 'tiên', 'trưa', 'lĩnh', 'biện', 'khỏe', 'xã', 'phấn', 'coi', 'nhở', 'lắp', 'tắc', 'phép', 'tạp', 'tả', 'màn', 'cửa', 'phổ', 'trí', 'logic', 'khái', 'hăng', 'chứng', 'văn', 'căng', 'tay', 'tầm', 'dồi', 'thoại', 'chí', 'nguồn', 'môi', 'tóm', 'kit', 'ty', 'tí', 'bó', 'trưởng', 'chả', 'copy', 'khắt'])\nVocab size 752\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"# np.append(word2vec_cbow.wv['vui'],word2vec_sg.wv['vui'])\nprint(len(word2vec_sg.wv['và']))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T04:01:56.557463Z","iopub.execute_input":"2025-01-29T04:01:56.558166Z","iopub.status.idle":"2025-01-29T04:01:57.145830Z","shell.execute_reply.started":"2025-01-29T04:01:56.558130Z","shell.execute_reply":"2025-01-29T04:01:57.144632Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","Cell \u001b[0;32mIn[36], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# np.append(word2vec_cbow.wv['vui'],word2vec_sg.wv['vui'])\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mword2vec_sg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwv\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvà\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/gensim/models/keyedvectors.py:403\u001b[0m, in \u001b[0;36mKeyedVectors.__getitem__\u001b[0;34m(self, key_or_keys)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get vector representation of `key_or_keys`.\u001b[39;00m\n\u001b[1;32m    390\u001b[0m \n\u001b[1;32m    391\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    400\u001b[0m \n\u001b[1;32m    401\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key_or_keys, _KEY_TYPES):\n\u001b[0;32m--> 403\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey_or_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m vstack([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_vector(key) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m key_or_keys])\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/gensim/models/keyedvectors.py:446\u001b[0m, in \u001b[0;36mKeyedVectors.get_vector\u001b[0;34m(self, key, norm)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_vector\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    423\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get the key's vector, as a 1D numpy array.\u001b[39;00m\n\u001b[1;32m    424\u001b[0m \n\u001b[1;32m    425\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    444\u001b[0m \n\u001b[1;32m    445\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 446\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m norm:\n\u001b[1;32m    448\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfill_norms()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/gensim/models/keyedvectors.py:420\u001b[0m, in \u001b[0;36mKeyedVectors.get_index\u001b[0;34m(self, key, default)\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m default\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 420\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKey \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not present\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mKeyError\u001b[0m: \"Key 'và' not present\""],"ename":"KeyError","evalue":"\"Key 'và' not present\"","output_type":"error"}],"execution_count":36},{"cell_type":"code","source":"stop here","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T03:49:37.763751Z","iopub.status.idle":"2025-01-29T03:49:37.764200Z","shell.execute_reply.started":"2025-01-29T03:49:37.763966Z","shell.execute_reply":"2025-01-29T03:49:37.763989Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\n\nrandom_std = 0.05\nrandom_mean = 0\nunk_vector = np.random.normal(random_mean, random_std, 300)\n\n# Pre-fill the embedding matrix with the unknown vector\nembedding_matrix = np.tile(unk_vector, (10000, 1))\n\n# Populate the embedding matrix\nfor word, i in tokenizer_data.word_index.items():\n    if i >= 10000:\n        continue\n    embedding_vector = embeddings_index.get(word)\n    if embedding_vector is not None:\n        # embedding_matrix[i] = np.append(word2vec_cbow.wv[w],word2vec_sg.wv[w])\n        embedding_matrix[i] = word2vec_cbow.wv[w]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T04:02:02.860897Z","iopub.execute_input":"2025-01-29T04:02:02.861347Z","iopub.status.idle":"2025-01-29T04:02:02.879958Z","shell.execute_reply.started":"2025-01-29T04:02:02.861304Z","shell.execute_reply":"2025-01-29T04:02:02.878995Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"def get_positional_encoding(max_seq_len, d_model):\n    pos = np.arange(max_seq_len)[:, np.newaxis]  # Shape: (max_seq_len, 1)\n    i = np.arange(d_model)[np.newaxis, :]       # Shape: (1, d_model)\n    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n    angle_rads = pos * angle_rates\n\n    # Apply sin to even indices and cos to odd indices\n    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n\n    positional_encoding = angle_rads[np.newaxis, ...]\n    return tf.cast(positional_encoding, dtype=tf.float32)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T03:49:37.768194Z","iopub.status.idle":"2025-01-29T03:49:37.768708Z","shell.execute_reply.started":"2025-01-29T03:49:37.768426Z","shell.execute_reply":"2025-01-29T03:49:37.768449Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def attention_layer(embedding):\n    np.random.seed(2004)\n    value = np.random.rand(3, 3)\n    W_Q = value.copy()\n    W_K = value.copy()\n    W_V = value.copy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T03:49:37.769762Z","iopub.status.idle":"2025-01-29T03:49:37.770406Z","shell.execute_reply.started":"2025-01-29T03:49:37.770159Z","shell.execute_reply":"2025-01-29T03:49:37.770184Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import Input, Embedding, Conv1D, MaxPool1D, Dropout, LayerNormalization\nfrom tensorflow.keras.layers import Bidirectional, LSTM, GRU, Concatenate, GlobalMaxPooling1D, Dense, MultiHeadAttention\nfrom tensorflow.keras.optimizers import AdamW\nfrom tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\nfrom sklearn.metrics import classification_report\n\ndef generate_model(data_vocab_size, embedding_matrix):\n    dropout_threshold = 0.3  \n    input_dim = data_vocab_size\n    output_dim = 300  \n    input_length = 130\n    initializer = tf.keras.initializers.GlorotNormal()\n    \n    input_layer = Input(shape=(input_length,))\n    feature = Embedding(input_dim=input_dim, output_dim=output_dim, \n                        embeddings_initializer=initializer, weights=[embedding_matrix])(input_layer)\n\n    feature = Dropout(0.5)(feature)  \n    # Convolutional Path\n    cnn_feature = Conv1D(filters=100, kernel_size=3, padding='same', activation='relu')(feature)  # Increased filters\n    cnn_feature = MaxPool1D()(cnn_feature)  # Reduces to 128\n    cnn_feature = Dropout(dropout_threshold)(cnn_feature)\n\n    # Recurrent Path\n\n    bi_lstm_feature = Bidirectional(LSTM(units=300, dropout=0.2, return_sequences=True,\n                                         kernel_initializer=initializer))(cnn_feature)  # Increased units\n    bi_lstm_feature = MaxPool1D()(bi_lstm_feature) \n    bi_lstm_feature = LayerNormalization()(bi_lstm_feature)\n    \n    # Self-Attention Layer\n    attention_output = MultiHeadAttention(num_heads=12, key_dim=32)(bi_lstm_feature, bi_lstm_feature)\n    attention_output = LayerNormalization()(attention_output)\n    attention_output = Dropout(dropout_threshold)(attention_output)  # Increased dropout rate\n    # Apply GlobalMaxPooling1D to both feature maps\n    cnn_pooled = GlobalMaxPooling1D()(cnn_feature)         \n    attention_pooled = GlobalMaxPooling1D()(attention_output)  \n\n    # Concatenate the pooled features\n    combine_feature = Concatenate()([cnn_pooled, attention_pooled])\n    combine_feature = LayerNormalization()(combine_feature)\n    combine_feature = Dropout(dropout_threshold)(combine_feature)  \n    \n    # Classification Layers\n    classifier = Dense(256, activation='relu')(combine_feature)  \n    classifier = Dropout(dropout_threshold)(classifier)  \n    classifier = Dense(64, activation='relu')(classifier)  \n    classifier = Dropout(dropout_threshold)(classifier)  \n    classifier = Dense(3, activation='softmax')(classifier)\n\n    model = tf.keras.Model(inputs=input_layer, outputs=classifier)\n    return model\n\nmodel_cnn_l = generate_model(10000, embedding_matrix)\nadam = Adam(learning_rate=1e-4, weight_decay=0.0)\nmodel_cnn_l.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n\nearly_stopping = EarlyStopping(monitor='val_accuracy', patience=50, restore_best_weights=True)\nhistory_cnn = model_cnn_l.fit(\n    x=test_features,\n    y=y_test,\n    validation_data=(dev_features, y_dev),\n    epochs=500,\n    batch_size=64,\n    callbacks=[early_stopping]\n)\nlabel_class = ['Positive', 'Neutral', 'Negative']\nmodel_cnn_l.evaluate(test_features, y_test)\npreds = model_cnn_l.predict(test_features)\npreds = tf.round(preds).numpy()\nprint(classification_report(y_test, preds, target_names=label_class, zero_division=0))\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n\ny_test_single_label = np.argmax(y_test, axis=1)\npreds_single_label = np.argmax(preds, axis=1)\n\ncm = confusion_matrix(y_test_single_label, preds_single_label, labels=[0, 1, 2])\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_class)\ndisp.plot()\nplt.gca().grid(False)\nplt.title('Bi-LSTM with Multi Head Attention')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T04:03:11.030024Z","iopub.execute_input":"2025-01-29T04:03:11.030748Z","iopub.status.idle":"2025-01-29T04:15:13.261255Z","shell.execute_reply.started":"2025-01-29T04:03:11.030708Z","shell.execute_reply":"2025-01-29T04:15:13.260424Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 185ms/step - accuracy: 0.4448 - loss: 1.1332 - val_accuracy: 0.5692 - val_loss: 0.8451\nEpoch 2/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 174ms/step - accuracy: 0.5260 - loss: 0.8918 - val_accuracy: 0.5925 - val_loss: 0.8155\nEpoch 3/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 172ms/step - accuracy: 0.5593 - loss: 0.8589 - val_accuracy: 0.5698 - val_loss: 0.8227\nEpoch 4/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 171ms/step - accuracy: 0.5530 - loss: 0.8801 - val_accuracy: 0.5723 - val_loss: 0.8135\nEpoch 5/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 174ms/step - accuracy: 0.5675 - loss: 0.8635 - val_accuracy: 0.5603 - val_loss: 0.8242\nEpoch 6/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 174ms/step - accuracy: 0.5618 - loss: 0.8395 - val_accuracy: 0.5780 - val_loss: 0.8187\nEpoch 7/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 172ms/step - accuracy: 0.5872 - loss: 0.8505 - val_accuracy: 0.6121 - val_loss: 0.7924\nEpoch 8/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 169ms/step - accuracy: 0.6163 - loss: 0.8106 - val_accuracy: 0.6260 - val_loss: 0.7915\nEpoch 9/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 173ms/step - accuracy: 0.6371 - loss: 0.8044 - val_accuracy: 0.6879 - val_loss: 0.7345\nEpoch 10/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 172ms/step - accuracy: 0.6844 - loss: 0.7271 - val_accuracy: 0.7517 - val_loss: 0.6206\nEpoch 11/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 171ms/step - accuracy: 0.7886 - loss: 0.5768 - val_accuracy: 0.7562 - val_loss: 0.6694\nEpoch 12/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 173ms/step - accuracy: 0.8245 - loss: 0.5132 - val_accuracy: 0.8339 - val_loss: 0.4444\nEpoch 13/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 172ms/step - accuracy: 0.8471 - loss: 0.4728 - val_accuracy: 0.8377 - val_loss: 0.4725\nEpoch 14/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 170ms/step - accuracy: 0.8455 - loss: 0.4409 - val_accuracy: 0.7890 - val_loss: 0.6293\nEpoch 15/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 168ms/step - accuracy: 0.8527 - loss: 0.4406 - val_accuracy: 0.8421 - val_loss: 0.4920\nEpoch 16/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 169ms/step - accuracy: 0.8609 - loss: 0.4276 - val_accuracy: 0.8572 - val_loss: 0.4634\nEpoch 17/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 171ms/step - accuracy: 0.8740 - loss: 0.3929 - val_accuracy: 0.7997 - val_loss: 0.5867\nEpoch 18/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 167ms/step - accuracy: 0.8755 - loss: 0.3862 - val_accuracy: 0.8787 - val_loss: 0.3719\nEpoch 19/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 169ms/step - accuracy: 0.8566 - loss: 0.4061 - val_accuracy: 0.8541 - val_loss: 0.5321\nEpoch 20/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 168ms/step - accuracy: 0.8656 - loss: 0.3960 - val_accuracy: 0.8579 - val_loss: 0.4691\nEpoch 21/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 171ms/step - accuracy: 0.8742 - loss: 0.3829 - val_accuracy: 0.8699 - val_loss: 0.4644\nEpoch 22/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 167ms/step - accuracy: 0.8803 - loss: 0.3662 - val_accuracy: 0.8699 - val_loss: 0.4296\nEpoch 23/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 170ms/step - accuracy: 0.8824 - loss: 0.3541 - val_accuracy: 0.8825 - val_loss: 0.3976\nEpoch 24/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 167ms/step - accuracy: 0.8858 - loss: 0.3645 - val_accuracy: 0.8383 - val_loss: 0.5786\nEpoch 25/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 169ms/step - accuracy: 0.8669 - loss: 0.3827 - val_accuracy: 0.8825 - val_loss: 0.3974\nEpoch 26/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 166ms/step - accuracy: 0.8744 - loss: 0.3798 - val_accuracy: 0.8793 - val_loss: 0.4143\nEpoch 27/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 168ms/step - accuracy: 0.8887 - loss: 0.3361 - val_accuracy: 0.8838 - val_loss: 0.3995\nEpoch 28/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 173ms/step - accuracy: 0.8904 - loss: 0.3503 - val_accuracy: 0.8812 - val_loss: 0.4618\nEpoch 29/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 167ms/step - accuracy: 0.8924 - loss: 0.3426 - val_accuracy: 0.8471 - val_loss: 0.5212\nEpoch 30/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 170ms/step - accuracy: 0.8932 - loss: 0.3314 - val_accuracy: 0.8863 - val_loss: 0.4016\nEpoch 31/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 169ms/step - accuracy: 0.8748 - loss: 0.3681 - val_accuracy: 0.8673 - val_loss: 0.5276\nEpoch 32/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 172ms/step - accuracy: 0.8929 - loss: 0.3342 - val_accuracy: 0.8920 - val_loss: 0.3480\nEpoch 33/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 169ms/step - accuracy: 0.8971 - loss: 0.3262 - val_accuracy: 0.8756 - val_loss: 0.3943\nEpoch 34/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 170ms/step - accuracy: 0.8900 - loss: 0.3192 - val_accuracy: 0.8825 - val_loss: 0.3767\nEpoch 35/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 169ms/step - accuracy: 0.8990 - loss: 0.3202 - val_accuracy: 0.8591 - val_loss: 0.4801\nEpoch 36/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 175ms/step - accuracy: 0.8954 - loss: 0.3258 - val_accuracy: 0.8920 - val_loss: 0.3382\nEpoch 37/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 171ms/step - accuracy: 0.8913 - loss: 0.3292 - val_accuracy: 0.8838 - val_loss: 0.3919\nEpoch 38/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 172ms/step - accuracy: 0.8902 - loss: 0.3163 - val_accuracy: 0.8699 - val_loss: 0.4729\nEpoch 39/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 173ms/step - accuracy: 0.8886 - loss: 0.3176 - val_accuracy: 0.8768 - val_loss: 0.4674\nEpoch 40/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 176ms/step - accuracy: 0.9095 - loss: 0.2791 - val_accuracy: 0.8901 - val_loss: 0.3406\nEpoch 41/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 172ms/step - accuracy: 0.9019 - loss: 0.2918 - val_accuracy: 0.8869 - val_loss: 0.3421\nEpoch 42/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 171ms/step - accuracy: 0.8924 - loss: 0.2992 - val_accuracy: 0.8857 - val_loss: 0.3797\nEpoch 43/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 174ms/step - accuracy: 0.9005 - loss: 0.2995 - val_accuracy: 0.8793 - val_loss: 0.4490\nEpoch 44/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 171ms/step - accuracy: 0.8989 - loss: 0.2972 - val_accuracy: 0.8680 - val_loss: 0.4147\nEpoch 45/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 171ms/step - accuracy: 0.8960 - loss: 0.3013 - val_accuracy: 0.8730 - val_loss: 0.3984\nEpoch 46/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 171ms/step - accuracy: 0.9070 - loss: 0.2652 - val_accuracy: 0.8812 - val_loss: 0.4283\nEpoch 47/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 173ms/step - accuracy: 0.9084 - loss: 0.2772 - val_accuracy: 0.8876 - val_loss: 0.3867\nEpoch 48/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 170ms/step - accuracy: 0.9080 - loss: 0.2771 - val_accuracy: 0.8806 - val_loss: 0.4319\nEpoch 49/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 171ms/step - accuracy: 0.9067 - loss: 0.2717 - val_accuracy: 0.8819 - val_loss: 0.3843\nEpoch 50/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 172ms/step - accuracy: 0.9220 - loss: 0.2666 - val_accuracy: 0.8730 - val_loss: 0.4153\nEpoch 51/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 174ms/step - accuracy: 0.9126 - loss: 0.2636 - val_accuracy: 0.8863 - val_loss: 0.3613\nEpoch 52/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 169ms/step - accuracy: 0.9004 - loss: 0.2876 - val_accuracy: 0.8863 - val_loss: 0.3582\nEpoch 53/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 168ms/step - accuracy: 0.9104 - loss: 0.2661 - val_accuracy: 0.8888 - val_loss: 0.3683\nEpoch 54/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 176ms/step - accuracy: 0.8980 - loss: 0.2879 - val_accuracy: 0.8768 - val_loss: 0.4260\nEpoch 55/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 174ms/step - accuracy: 0.9148 - loss: 0.2469 - val_accuracy: 0.8806 - val_loss: 0.4056\nEpoch 56/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 171ms/step - accuracy: 0.9159 - loss: 0.2455 - val_accuracy: 0.8756 - val_loss: 0.4212\nEpoch 57/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 173ms/step - accuracy: 0.9107 - loss: 0.2666 - val_accuracy: 0.8737 - val_loss: 0.3952\nEpoch 58/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 174ms/step - accuracy: 0.9198 - loss: 0.2535 - val_accuracy: 0.8831 - val_loss: 0.3558\nEpoch 59/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 171ms/step - accuracy: 0.9217 - loss: 0.2409 - val_accuracy: 0.8812 - val_loss: 0.3615\nEpoch 60/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 173ms/step - accuracy: 0.9159 - loss: 0.2452 - val_accuracy: 0.8838 - val_loss: 0.3757\nEpoch 61/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 171ms/step - accuracy: 0.9196 - loss: 0.2335 - val_accuracy: 0.8838 - val_loss: 0.3787\nEpoch 62/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 176ms/step - accuracy: 0.9198 - loss: 0.2360 - val_accuracy: 0.8863 - val_loss: 0.3811\nEpoch 63/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 171ms/step - accuracy: 0.9172 - loss: 0.2414 - val_accuracy: 0.8781 - val_loss: 0.4054\nEpoch 64/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 173ms/step - accuracy: 0.9335 - loss: 0.2143 - val_accuracy: 0.8850 - val_loss: 0.3578\nEpoch 65/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 173ms/step - accuracy: 0.9107 - loss: 0.2559 - val_accuracy: 0.8812 - val_loss: 0.4050\nEpoch 66/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 171ms/step - accuracy: 0.9212 - loss: 0.2397 - val_accuracy: 0.8812 - val_loss: 0.3607\nEpoch 67/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 169ms/step - accuracy: 0.9123 - loss: 0.2594 - val_accuracy: 0.8743 - val_loss: 0.4113\nEpoch 68/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 168ms/step - accuracy: 0.9204 - loss: 0.2284 - val_accuracy: 0.8743 - val_loss: 0.4003\nEpoch 69/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 176ms/step - accuracy: 0.9194 - loss: 0.2549 - val_accuracy: 0.8825 - val_loss: 0.3845\nEpoch 70/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 169ms/step - accuracy: 0.9335 - loss: 0.2063 - val_accuracy: 0.8711 - val_loss: 0.3834\nEpoch 71/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 167ms/step - accuracy: 0.9195 - loss: 0.2436 - val_accuracy: 0.8812 - val_loss: 0.3914\nEpoch 72/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 170ms/step - accuracy: 0.9346 - loss: 0.2124 - val_accuracy: 0.8699 - val_loss: 0.4158\nEpoch 73/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 174ms/step - accuracy: 0.9250 - loss: 0.2171 - val_accuracy: 0.8661 - val_loss: 0.4626\nEpoch 74/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 169ms/step - accuracy: 0.9187 - loss: 0.2414 - val_accuracy: 0.8831 - val_loss: 0.3860\nEpoch 75/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 168ms/step - accuracy: 0.9272 - loss: 0.2095 - val_accuracy: 0.8756 - val_loss: 0.4095\nEpoch 76/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 171ms/step - accuracy: 0.9319 - loss: 0.2209 - val_accuracy: 0.8743 - val_loss: 0.4595\nEpoch 77/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 173ms/step - accuracy: 0.9270 - loss: 0.2226 - val_accuracy: 0.8819 - val_loss: 0.4256\nEpoch 78/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 175ms/step - accuracy: 0.9134 - loss: 0.2338 - val_accuracy: 0.8692 - val_loss: 0.3985\nEpoch 79/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 171ms/step - accuracy: 0.9181 - loss: 0.2493 - val_accuracy: 0.8737 - val_loss: 0.4373\nEpoch 80/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 168ms/step - accuracy: 0.9307 - loss: 0.2089 - val_accuracy: 0.8680 - val_loss: 0.4459\nEpoch 81/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 174ms/step - accuracy: 0.9259 - loss: 0.2148 - val_accuracy: 0.8800 - val_loss: 0.4016\nEpoch 82/500\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 171ms/step - accuracy: 0.9282 - loss: 0.2052 - val_accuracy: 0.8711 - val_loss: 0.3944\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.8969 - loss: 0.2923\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step\n              precision    recall  f1-score   support\n\n    Positive       0.93      0.87      0.90      1409\n     Neutral       0.00      0.00      0.00       167\n    Negative       0.92      0.94      0.93      1590\n\n   micro avg       0.92      0.86      0.89      3166\n   macro avg       0.62      0.60      0.61      3166\nweighted avg       0.87      0.86      0.87      3166\n samples avg       0.86      0.86      0.86      3166\n\n","output_type":"stream"},{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"Text(0.5, 1.0, 'Bi-LSTM with Multi Head Attention')"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 2 Axes>","image/png":"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"},"metadata":{}}],"execution_count":38},{"cell_type":"code","source":"model_cnn_l.save('model_cnn_l.keras')\nmodel_cnn_l.load_weights(\"model_cnn_l.keras\")\nmodel_cnn_l.evaluate(test_features, y_test)\n\nfrom sklearn.metrics import classification_report\nlabel_class = ['Tiêu cực', 'Trung Lập', 'Tích cực']\nmodel_cnn_l.load_weights('/kaggle/working/model_cnn_l.keras')\nmodel_cnn_l.evaluate(test_features, y_test)\n\npreds = model_cnn_l.predict(test_features)\npreds = tf.round(preds).numpy()\n\nprint(classification_report(y_test, preds, target_names=label_class, zero_division=0))\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n\ny_test_single_label = np.argmax(y_test, axis=1)\npreds_single_label = np.argmax(preds, axis=1)\n\ncm = confusion_matrix(y_test_single_label, preds_single_label, labels=[0, 1, 2])\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_class)\ndisp.plot()\nplt.gca().grid(False)\nplt.title('Bi-LSTM with Multi Head Attention')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T03:49:37.773419Z","iopub.status.idle":"2025-01-29T03:49:37.774031Z","shell.execute_reply.started":"2025-01-29T03:49:37.773654Z","shell.execute_reply":"2025-01-29T03:49:37.773752Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install tf-models-official","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T03:49:37.775376Z","iopub.status.idle":"2025-01-29T03:49:37.775853Z","shell.execute_reply.started":"2025-01-29T03:49:37.775591Z","shell.execute_reply":"2025-01-29T03:49:37.775635Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import SpatialDropout1D, Input, Embedding, Conv1D, MaxPool1D, Dropout, BatchNormalization, GlobalMaxPooling1D, Dense, Bidirectional, LSTM, LayerNormalization, MultiHeadAttention, Concatenate\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nimport keras_tuner as kt\nimport tensorflow_models as tfm \n\ndef build_model(hp):\n    input_dim = data_vocab_size  \n    output_dim = 300\n    input_length = 110\n    initializer = tf.keras.initializers.GlorotNormal()\n\n    input_layer = Input(shape=(input_length,))\n    feature = Embedding(input_dim=input_dim, output_dim=output_dim, \n                        embeddings_initializer=initializer, weights=[embedding_matrix])(input_layer)\n    feature = SpatialDropout1D(rate=hp.Float('features_dropout', min_value=0.0, max_value=0.6, step=0.1))(feature)\n    \n\n    cnn_feature_dropout = hp.Float('cnn_feature_dropout', min_value=0.0, max_value=0.6, step=0.1)\n    # Convolutional Path\n    cnn_feature1 = Conv1D(filters=hp.Int('filters_1', min_value=64, max_value=256, step=64), \n                          kernel_size=3, padding='same', activation='relu')(feature)\n    cnn_feature1 = MaxPool1D()(cnn_feature1)\n    cnn_feature1 = LayerNormalization()(cnn_feature1)\n    cnn_feature1 = Dropout(cnn_feature_dropout)(cnn_feature1)\n    cnn_feature2 = Conv1D(filters=hp.Int('filters_2', min_value=64, max_value=256, step=64), \n                          kernel_size=5, padding='same', activation='relu')(cnn_feature1)\n    cnn_feature2 = MaxPool1D()(cnn_feature2)\n    cnn_feature2 = LayerNormalization()(cnn_feature2)\n    cnn_feature2 = Dropout(cnn_feature_dropout)(cnn_feature2)\n    cnn_feature3 = Conv1D(filters=hp.Int('filters_3', min_value=128, max_value=512, step=128), \n                          kernel_size=7, padding='same', activation='relu')(cnn_feature2)\n    cnn_feature3 = MaxPool1D()(cnn_feature3)\n    cnn_feature3 = LayerNormalization()(cnn_feature3)\n    cnn_feature3 = Dropout(cnn_feature_dropout)(cnn_feature3)\n    cnn_feature4 = Conv1D(filters=hp.Int('filters_4', min_value=128, max_value=512, step=128), \n                          kernel_size=9, padding='same', activation='relu')(cnn_feature3)\n    cnn_feature4 = MaxPool1D()(cnn_feature4)\n    cnn_feature4 = LayerNormalization()(cnn_feature4)\n    cnn_feature4 = Dropout(cnn_feature_dropout)(cnn_feature4)\n    cnn_pooled = GlobalMaxPooling1D()(cnn_feature4)\n    cnn_pooled_dropout = hp.Float('cnn_pooled_dropout', min_value=0.0, max_value=0.6, step=0.1)\n    cnn_pooled = Dropout(cnn_pooled_dropout)(cnn_pooled)\n\n    bi_lstm_feature_dropout = hp.Float('bi_lstm_feature_dropout', min_value=0.0, max_value=0.6, step=0.1)\n    # LSTM Path\n    bi_lstm_feature = Bidirectional(LSTM(units=hp.Int('lstm_units_1', min_value=128, max_value=512, step=128), \n                                         dropout=bi_lstm_feature_dropout, return_sequences=True, kernel_initializer=initializer))(cnn_feature4)\n    bi_lstm_feature = MaxPool1D()(bi_lstm_feature)\n    bi_lstm_feature = LayerNormalization()(bi_lstm_feature)\n    bi_lstm_feature = Dropout(bi_lstm_feature_dropout)(bi_lstm_feature)\n    bi_lstm_feature = Bidirectional(LSTM(units=hp.Int('lstm_units_2', min_value=128, max_value=512, step=128), \n                                         dropout=bi_lstm_feature_dropout, return_sequences=True, kernel_initializer=initializer))(bi_lstm_feature)\n    bi_lstm_feature = MaxPool1D()(bi_lstm_feature)\n    bi_lstm_pooled = GlobalMaxPooling1D()(bi_lstm_feature)\n    bi_lstm_pooled = LayerNormalization()(bi_lstm_pooled)\n    bi_lstm_pooled_dropout = hp.Float('bi_lstm_pooled_dropout', min_value=0.0, max_value=0.6, step=0.1)\n    bi_lstm_pooled = Dropout(bi_lstm_pooled_dropout)(bi_lstm_pooled)\n    \n    # Attention Path\n    attention_output = MultiHeadAttention(num_heads=hp.Int('num_heads', min_value=4, max_value=12, step=4), \n                                          key_dim=hp.Int('key_dim', min_value=4, max_value=64, step=4))(bi_lstm_feature, bi_lstm_feature)\n    attention_pooled = GlobalMaxPooling1D()(attention_output)\n    attention_pooled = LayerNormalization()(attention_pooled)\n    attention_pooled_dropout = hp.Float('attention_pooled_dropout', min_value=0.0, max_value=0.6, step=0.1)\n    attention_pooled = Dropout(attention_pooled_dropout)(attention_pooled)\n\n    # attention_combine_layer = MultiHeadAttention(num_heads=4, key_dim=64)\n    # attention_output = attention_combine_layer(query=bi_lstm_pooled, key=attention_pooled, value=cnn_pooled)\n    # combine_feature = Concatenate()([attention_output, bi_lstm_pooled, cnn_pooled])\n    \n    # Combine Features\n    combine_feature = Concatenate()([bi_lstm_pooled, attention_pooled, cnn_pooled])\n    combine_feature = LayerNormalization()(combine_feature)\n    combine_feature_dropout = hp.Float('combine_feature_dropout', min_value=0.0, max_value=0.6, step=0.1)\n    combine_feature = Dropout(combine_feature_dropout)(combine_feature)\n\n    classifier_dropout = hp.Float('classifier_dropout', min_value=0.0, max_value=0.6, step=0.1)\n    # Dense Layers\n    classifier = Dense(units=hp.Int('dense_units_1', min_value=128, max_value=512, step=128), activation='relu')(combine_feature)\n    classifier = Dropout(classifier_dropout)(classifier)\n    classifier = Dense(units=hp.Int('dense_units_2', min_value=64, max_value=256, step=64), activation='relu')(classifier)\n    classifier = Dropout(classifier_dropout)(classifier)\n    classifier = Dense(3, activation='softmax')(classifier)\n\n    model = tf.keras.Model(inputs=input_layer, outputs=classifier)\n\n    # Compile the model\n    learning_rate = hp.Choice('learning_rate', values=[1e-4, 4e-4, 1e-5, 4e-5])\n    optimizer = Adam(learning_rate=learning_rate)\n    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T03:49:37.777870Z","iopub.status.idle":"2025-01-29T03:49:37.778334Z","shell.execute_reply.started":"2025-01-29T03:49:37.778097Z","shell.execute_reply":"2025-01-29T03:49:37.778122Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!rm -rf /kaggle/working/my_tuning_dir_1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T03:49:37.779328Z","iopub.status.idle":"2025-01-29T03:49:37.779784Z","shell.execute_reply.started":"2025-01-29T03:49:37.779535Z","shell.execute_reply":"2025-01-29T03:49:37.779559Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tuner = kt.Hyperband(\n    build_model,\n    objective='val_accuracy',\n    max_epochs=50,\n    factor=3,\n    directory='my_tuning_dir_1',\n    project_name='cnn_lstm_attention_tuning'\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T03:49:37.781103Z","iopub.status.idle":"2025-01-29T03:49:37.781555Z","shell.execute_reply.started":"2025-01-29T03:49:37.781319Z","shell.execute_reply":"2025-01-29T03:49:37.781342Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n\n# Tạo callback ModelCheckpoint \ncheckpoint_callback = ModelCheckpoint(\n    filepath='best_model.weights.h5',    # Tên file bạn muốn lưu #không cho xài keras\n    monitor='val_accuracy',      # Metric để theo dõi\n    mode='max',                  # Lựa chọn \"max\" vì ta muốn val_accuracy lớn nhất\n    save_best_only=True,         # Chỉ lưu lại model tốt nhất\n    save_weights_only=True,      # Chỉ lưu trọng số (không cần lưu cấu trúc)\n    verbose=1\n)\n\n# tuner.search(\n#     x=train_features,\n#     y=y_train,\n#     validation_data=(dev_features, y_dev),\n#     epochs=50,\n#     batch_size=64,\n#     callbacks=[EarlyStopping(monitor='val_accuracy', patience=8)]\n# )\n\ntuner.search(\n    x=train_features,\n    y=y_train,\n    validation_data=(dev_features, y_dev),\n    epochs=50,\n    batch_size=64,\n    callbacks=[EarlyStopping(monitor='val_accuracy', patience=8),\n               checkpoint_callback]  # Thêm callback này\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T03:49:37.783404Z","iopub.status.idle":"2025-01-29T03:49:37.783871Z","shell.execute_reply.started":"2025-01-29T03:49:37.783640Z","shell.execute_reply":"2025-01-29T03:49:37.783664Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"best_model = tuner.get_best_models(num_models=1)[0]\nbest_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]\n\nprint(\"Best Hyperparameters:\")\nprint(best_hyperparameters.values)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T03:49:37.785384Z","iopub.status.idle":"2025-01-29T03:49:37.785860Z","shell.execute_reply.started":"2025-01-29T03:49:37.785598Z","shell.execute_reply":"2025-01-29T03:49:37.785642Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history = best_model.fit(\n    x=train_features,\n    y=y_train,\n    validation_data=(dev_features, y_dev),\n    epochs=500,\n    batch_size=64,\n    callbacks=[EarlyStopping(monitor='val_accuracy', patience=100, restore_best_weights=True)]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T03:49:37.786871Z","iopub.status.idle":"2025-01-29T03:49:37.787760Z","shell.execute_reply.started":"2025-01-29T03:49:37.787452Z","shell.execute_reply":"2025-01-29T03:49:37.787482Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from datetime import datetime\n\n# Lấy ngày tháng năm hiện tại\nnow = datetime.now()\ndate_string= now.strftime(\"%d-%m-%Y\")  # Định dạng: ngày-tháng-năm\n\nbest_model.save('model_multi_cnn_multi_lstm_multihead_attention_fined_tuned.keras')\nbest_model.load_weights(\"model_multi_cnn_multi_lstm_multihead_attention_fined_tuned.keras\")\nbest_model.evaluate(test_features, y_test)\n\nfrom sklearn.metrics import classification_report\nlabel_class = ['Tiêu cực', 'Trung Lập', 'Tích cực']\nbest_model.load_weights('/kaggle/working/model_multi_cnn_multi_lstm_multihead_attention_fined_tuned.keras')\nbest_model.evaluate(test_features, y_test)\n\npreds = best_model.predict(test_features)\npreds = tf.round(preds).numpy()\n\nprint(classification_report(y_test, preds, target_names=label_class, zero_division=0))\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nlabel_class = ['Tiêu cực', 'Trung Lập', 'Tích cực']\n\n\ny_test_single_label = np.argmax(y_test, axis=1)\npreds_single_label = np.argmax(preds, axis=1)\n\ncm = confusion_matrix(y_test_single_label, preds_single_label, labels=[0, 1, 2])\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_class)\ndisp.plot()\nplt.gca().grid(False)\nplt.title('Multi CNN Bi-LSTM')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T03:49:37.789253Z","iopub.status.idle":"2025-01-29T03:49:37.789775Z","shell.execute_reply.started":"2025-01-29T03:49:37.789470Z","shell.execute_reply":"2025-01-29T03:49:37.789494Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import (\n    Input, Embedding, Conv1D, Conv2D, MaxPool1D, MaxPooling2D, Dropout, \n    BatchNormalization, GlobalMaxPooling1D, GlobalMaxPooling2D, Dense, \n    Bidirectional, LSTM, LayerNormalization, MultiHeadAttention, Concatenate, Reshape\n)\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\n\ndef generate_model_with_conv2d(data_vocab_size, embedding_matrix=None):\n    dropout_threshold = 0.1  \n    input_dim = data_vocab_size\n    output_dim = 300  \n    input_length = 110\n    initializer = tf.keras.initializers.GlorotNormal()\n    \n    input_layer = Input(shape=(input_length,))\n    \n    # Embedding Layer\n    if embedding_matrix is not None:\n        feature = Embedding(\n            input_dim=input_dim, \n            output_dim=output_dim, \n            embeddings_initializer=initializer, \n            weights=[embedding_matrix],\n            input_length=input_length,\n            trainable=False  # Set to True if you want to fine-tune embeddings\n        )(input_layer)\n    else:\n        feature = Embedding(\n            input_dim=input_dim, \n            output_dim=output_dim, \n            embeddings_initializer=initializer,\n            input_length=input_length\n        )(input_layer)\n    \n    feature = Dropout(0.5)(feature)  \n    \n    ### Conv1D Path ###\n    cnn_feature1 = Conv1D(filters=128, kernel_size=3, padding='same', activation='relu')(feature)\n    cnn_feature1 = MaxPool1D()(cnn_feature1)\n    cnn_feature1 = BatchNormalization()(cnn_feature1)\n    cnn_feature1 = Dropout(dropout_threshold)(cnn_feature1)\n\n    cnn_feature2 = Conv1D(filters=128, kernel_size=5, padding='same', activation='relu')(cnn_feature1)\n    cnn_feature2 = MaxPool1D()(cnn_feature2)\n    cnn_feature2 = BatchNormalization()(cnn_feature2)\n    cnn_feature2 = Dropout(dropout_threshold)(cnn_feature2)\n\n    cnn_feature3 = Conv1D(filters=256, kernel_size=7, padding='same', activation='relu')(cnn_feature2)\n    cnn_feature3 = MaxPool1D()(cnn_feature3)\n    cnn_feature3 = BatchNormalization()(cnn_feature3)\n    cnn_feature3 = Dropout(dropout_threshold)(cnn_feature3)\n\n    cnn_feature4 = Conv1D(filters=256, kernel_size=9, padding='same', activation='relu')(cnn_feature3)\n    cnn_feature4 = MaxPool1D()(cnn_feature4)\n    cnn_feature4 = BatchNormalization()(cnn_feature4)\n    cnn_feature4 = Dropout(dropout_threshold)(cnn_feature4)\n\n    cnn_pooled = GlobalMaxPooling1D()(cnn_feature4)\n\n    ### Bi-LSTM and Attention Path ###\n    bi_lstm_feature = Bidirectional(LSTM(units=300, dropout=0.2, return_sequences=True,\n                                         kernel_initializer=initializer))(cnn_feature4)\n    bi_lstm_feature = MaxPool1D()(bi_lstm_feature) \n    bi_lstm_feature = LayerNormalization()(bi_lstm_feature)\n    bi_lstm_feature = Bidirectional(LSTM(units=128, dropout=0.2, return_sequences=True,\n                                         kernel_initializer=initializer))(bi_lstm_feature)\n    bi_lstm_feature = MaxPool1D()(bi_lstm_feature) \n    bi_lstm_feature = LayerNormalization()(bi_lstm_feature)\n    bi_lstm_pooled = GlobalMaxPooling1D()(bi_lstm_feature)\n    bi_lstm_pooled = Dropout(dropout_threshold)(bi_lstm_pooled)\n\n    attention_output = MultiHeadAttention(num_heads=12, key_dim=32)(bi_lstm_feature, bi_lstm_feature)\n    attention_output = LayerNormalization()(attention_output)\n    attention_pooled = GlobalMaxPooling1D()(attention_output)  \n    attention_pooled = Dropout(dropout_threshold)(attention_pooled)\n\n    ### Conv2D Path ###\n    # Reshape for Conv2D: (batch_size, height, width, channels)\n    conv2d_input = Reshape((input_length, output_dim, 1))(feature)  # (batch_size, 110, 300, 1)\n\n    conv2d_layer1 = Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding='same')(conv2d_input)\n    conv2d_layer1 = MaxPooling2D(pool_size=(2,2))(conv2d_layer1)\n    conv2d_layer1 = BatchNormalization()(conv2d_layer1)\n    conv2d_layer1 = Dropout(dropout_threshold)(conv2d_layer1)\n\n    conv2d_layer2 = Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same')(conv2d_layer1)\n    conv2d_layer2 = MaxPooling2D(pool_size=(2,2))(conv2d_layer2)\n    conv2d_layer2 = BatchNormalization()(conv2d_layer2)\n    conv2d_pooled = GlobalMaxPooling2D()(conv2d_layer2)  # (batch_size, features)\n    conv2d_layer2 = Dropout(dropout_threshold)(conv2d_pooled)\n\n    ### Combine All Features ###\n    combine_feature = Concatenate()([bi_lstm_pooled, attention_pooled, cnn_pooled, conv2d_pooled])\n    combine_feature = LayerNormalization()(combine_feature)\n    combine_feature = Dropout(dropout_threshold)(combine_feature)\n\n    # Dense layers with L2 regularization (optional)\n    classifier = Dense(256, activation='relu')(classifier)\n    classifier = Dropout(dropout_threshold)(classifier)\n    classifier = Dense(64, activation='relu')(classifier)\n    classifier = Dropout(dropout_threshold)(classifier)\n    classifier = Dense(3, activation='softmax')(classifier)  # Final output layer\n\n    model = Model(inputs=input_layer, outputs=classifier)\n    return model\n\n# Example usage:\n# data_vocab_size = 3636  # Replace with your actual vocab size\n# embedding_matrix = ...    # Define or load your embedding matrix if available\nmodel_cnn = generate_model_with_conv2d(data_vocab_size, embedding_matrix=embedding_matrix)\n\nadam = Adam(learning_rate=1e-4)\nmodel_cnn.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\nmodel_cnn.summary()\n\nearly_stopping = EarlyStopping(monitor='val_accuracy', patience=500, restore_best_weights=True)\n\nhistory_cnn = model_cnn.fit(\n    x=train_features,\n    y=y_train,\n    validation_data=(dev_features, y_dev),\n    epochs=500,\n    batch_size=64,\n    callbacks=[early_stopping]\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T03:49:37.791071Z","iopub.status.idle":"2025-01-29T03:49:37.791523Z","shell.execute_reply.started":"2025-01-29T03:49:37.791294Z","shell.execute_reply":"2025-01-29T03:49:37.791318Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from datetime import datetime\n\n# Lấy ngày tháng năm hiện tại\nnow = datetime.now()\ndate_string= now.strftime(\"%d-%m-%Y\")  # Định dạng: ngày-tháng-năm\n\n# model_cnn.save('model_multi_cnn2d_multi_lstm_multihead_attention.keras')\n# model_cnn.load_weights(\"model_multi_cnn2d_multi_lstm_multihead_attention.keras\")\nmodel_cnn.evaluate(test_features, y_test)\n\nfrom sklearn.metrics import classification_report\nlabel_class = ['Tiêu cực', 'Trung Lập', 'Tích cực']\n# model_cnn.load_weights('/kaggle/working/model_multi_cnn2d_multi_lstm_multihead_attention.keras')\nmodel_cnn.evaluate(test_features, y_test)\n\npreds = model_cnn.predict(test_features)\npreds = tf.round(preds).numpy()\n\nprint(classification_report(y_test, preds, target_names=label_class, zero_division=0))\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nlabel_class = ['Tiêu cực', 'Trung Lập', 'Tích cực']\n\n\ny_test_single_label = np.argmax(y_test, axis=1)\npreds_single_label = np.argmax(preds, axis=1)\n\ncm = confusion_matrix(y_test_single_label, preds_single_label, labels=[0, 1, 2])\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_class)\ndisp.plot()\nplt.gca().grid(False)\nplt.title('Bi-LSTM')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T03:49:37.793480Z","iopub.status.idle":"2025-01-29T03:49:37.793838Z","shell.execute_reply.started":"2025-01-29T03:49:37.793654Z","shell.execute_reply":"2025-01-29T03:49:37.793675Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import keras_tuner as kt\nimport tensorflow as tf\nfrom tensorflow.keras.layers import (\n    Input, Embedding, Conv1D, MaxPool1D, Dropout, \n    BatchNormalization, GlobalMaxPooling1D, Bidirectional, LSTM, \n    LayerNormalization, MultiHeadAttention, Concatenate, Reshape, Dense\n)\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\n\ndef generate_model_with_tuner(hp):\n    dropout_threshold = hp.Float('dropout_threshold', min_value=0.1, max_value=0.5, step=0.1, default=0.2)\n    input_dim = data_vocab_size\n    output_dim = 300\n    input_length = 110\n    initializer = tf.keras.initializers.GlorotNormal()\n    \n    input_layer = Input(shape=(input_length,))\n    \n    # Embedding Layer\n    if embedding_matrix is not None:\n        feature = Embedding(\n            input_dim=input_dim, \n            output_dim=output_dim, \n            embeddings_initializer=initializer, \n            weights=[embedding_matrix],\n            input_length=input_length,\n            trainable=False\n        )(input_layer)\n    else:\n        feature = Embedding(\n            input_dim=input_dim, \n            output_dim=output_dim, \n            embeddings_initializer=initializer,\n            input_length=input_length\n        )(input_layer)\n    \n    feature = Dropout(dropout_threshold)(feature)  \n    \n    ### Conv1D Path ###\n    filters_1 = hp.Int('filters_1', min_value=64, max_value=256, step=64, default=128)\n    filters_2 = hp.Int('filters_2', min_value=64, max_value=256, step=64, default=128)\n    filters_3 = hp.Int('filters_3', min_value=128, max_value=512, step=128, default=256)\n\n    cnn_feature1 = Conv1D(filters=filters_1, kernel_size=3, padding='same', activation='relu')(feature)\n    cnn_feature1 = MaxPool1D()(cnn_feature1)\n    cnn_feature1 = BatchNormalization()(cnn_feature1)\n    cnn_feature1 = Dropout(dropout_threshold)(cnn_feature1)\n\n    cnn_feature2 = Conv1D(filters=filters_2, kernel_size=5, padding='same', activation='relu')(cnn_feature1)\n    cnn_feature2 = MaxPool1D()(cnn_feature2)\n    cnn_feature2 = BatchNormalization()(cnn_feature2)\n    cnn_feature2 = Dropout(dropout_threshold)(cnn_feature2)\n\n    cnn_feature3 = Conv1D(filters=filters_3, kernel_size=7, padding='same', activation='relu')(cnn_feature2)\n    cnn_feature3 = MaxPool1D()(cnn_feature3)\n    cnn_feature3 = BatchNormalization()(cnn_feature3)\n    cnn_feature3 = Dropout(dropout_threshold)(cnn_feature3)\n\n    cnn_pooled = GlobalMaxPooling1D()(cnn_feature3)\n\n    ### Bi-LSTM and Attention Path ###\n    bi_lstm_units_1 = hp.Int('bi_lstm_units_1', min_value=128, max_value=512, step=128, default=300)\n    bi_lstm_units_2 = hp.Int('bi_lstm_units_2', min_value=64, max_value=256, step=64, default=128)\n    \n    bi_lstm_feature = Bidirectional(LSTM(units=bi_lstm_units_1, dropout=0.2, return_sequences=True,\n                                         kernel_initializer=initializer))(cnn_feature3)\n    bi_lstm_feature = MaxPool1D()(bi_lstm_feature) \n    bi_lstm_feature = LayerNormalization()(bi_lstm_feature)\n    bi_lstm_feature = Bidirectional(LSTM(units=bi_lstm_units_2, dropout=0.2, return_sequences=True,\n                                         kernel_initializer=initializer))(bi_lstm_feature)\n    bi_lstm_feature = MaxPool1D()(bi_lstm_feature) \n    bi_lstm_feature = LayerNormalization()(bi_lstm_feature)\n    bi_lstm_pooled = GlobalMaxPooling1D()(bi_lstm_feature)\n    bi_lstm_pooled = Dropout(dropout_threshold)(bi_lstm_pooled)\n\n    attention_output = MultiHeadAttention(num_heads=12, key_dim=32)(bi_lstm_feature, bi_lstm_feature)\n    attention_output = LayerNormalization()(attention_output)\n    attention_pooled = GlobalMaxPooling1D()(attention_output)  \n    attention_pooled = Dropout(dropout_threshold)(attention_pooled)\n\n    ### Conv2D Path ###\n    conv2d_filters_1 = hp.Int('conv2d_filters_1', min_value=16, max_value=64, step=16, default=32)\n    conv2d_filters_2 = hp.Int('conv2d_filters_2', min_value=32, max_value=128, step=32, default=64)\n    \n    conv2d_input = Reshape((input_length, output_dim, 1))(feature)\n\n    conv2d_layer1 = Conv2D(filters=conv2d_filters_1, kernel_size=(3,3), activation='relu', padding='same')(conv2d_input)\n    conv2d_layer1 = MaxPooling2D(pool_size=(2,2))(conv2d_layer1)\n    conv2d_layer1 = BatchNormalization()(conv2d_layer1)\n    conv2d_layer1 = Dropout(dropout_threshold)(conv2d_layer1)\n\n    conv2d_layer2 = Conv2D(filters=conv2d_filters_2, kernel_size=(3,3), activation='relu', padding='same')(conv2d_layer1)\n    conv2d_layer2 = MaxPooling2D(pool_size=(2,2))(conv2d_layer2)\n    conv2d_layer2 = BatchNormalization()(conv2d_layer2)\n    conv2d_pooled = GlobalMaxPooling2D()(conv2d_layer2)  \n    conv2d_layer2 = Dropout(dropout_threshold)(conv2d_pooled)\n\n    ### Combine All Features ###\n    combine_feature = Concatenate()([bi_lstm_pooled, attention_pooled, cnn_pooled, conv2d_pooled])\n    combine_feature = LayerNormalization()(combine_feature)\n    combine_feature = Dropout(dropout_threshold)(combine_feature)\n\n    # Dense layers with L2 regularization (optional)\n    dense_units_1 = hp.Int('dense_units_1', min_value=128, max_value=512, step=128, default=256)\n    dense_units_2 = hp.Int('dense_units_2', min_value=64, max_value=256, step=64, default=64)\n    \n    classifier = Dense(dense_units_1, activation='relu')(combine_feature)\n    classifier = Dropout(dropout_threshold)(classifier)\n    classifier = Dense(dense_units_2, activation='relu')(classifier)\n    classifier = Dropout(dropout_threshold)(classifier)\n    classifier = Dense(3, activation='softmax')(classifier)  # Final output layer\n\n    model = Model(inputs=input_layer, outputs=classifier)\n    model.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n    return model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T03:49:37.794894Z","iopub.status.idle":"2025-01-29T03:49:37.795214Z","shell.execute_reply.started":"2025-01-29T03:49:37.795063Z","shell.execute_reply":"2025-01-29T03:49:37.795080Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Xác định Hyperparameters\ntuner = kt.Hyperband(\n    generate_model_with_tuner,\n    objective='val_accuracy',\n    max_epochs=10,\n    factor=3,\n    directory='conv2d_lstm_attention',\n    project_name='conv2d_lstm_attention'\n)\n\n# Tuning model\ntuner.search(\n    x=train_features,\n    y=y_train,\n    validation_data=(dev_features, y_dev),\n    epochs=50,\n    batch_size=64,\n    callbacks=[EarlyStopping(monitor='val_accuracy', patience=8)]  # Thêm callback này\n)\n\n# Lấy mô hình tốt nhất\nbest_model = tuner.get_best_models(num_models=1)[0]\nbest_model.summary()\n\n# Compile lại mô hình tốt nhất\n\n\n# Huấn luyện mô hình với early stopping\nearly_stopping = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\nhistory_cnn = best_model.fit(\n    train_features,\n    y_train,\n    validation_data=(dev_features, y_dev),\n    epochs=500,\n    batch_size=64,\n    callbacks=[early_stopping]\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T03:49:37.796355Z","iopub.status.idle":"2025-01-29T03:49:37.796726Z","shell.execute_reply.started":"2025-01-29T03:49:37.796534Z","shell.execute_reply":"2025-01-29T03:49:37.796551Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import (\n    Input, Embedding, Conv1D, MaxPool1D, Dropout, LayerNormalization,\n    Bidirectional, LSTM, Concatenate, GlobalMaxPooling1D, Dense, MultiHeadAttention\n)\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import AdamW\n\ndef generate_model_1(data_vocab_size, embedding_matrix):\n    dropout_threshold = 0.1  \n    input_dim = data_vocab_size\n    output_dim = 300  \n    input_length = 150\n    initializer = tf.keras.initializers.GlorotNormal()\n    \n    input_layer = Input(shape=(input_length,), name='input_layer')\n    \n    # Embedding Layer\n    embedding = Embedding(\n        input_dim=input_dim,\n        output_dim=output_dim, \n        embeddings_initializer=initializer,\n        weights=[embedding_matrix],\n        trainable=True,\n        name='embedding_layer'\n    )(input_layer)\n\n    # Recurrent Path (LSTM) - Moved Before CNN\n    bi_lstm_feature = Bidirectional(\n        LSTM(\n            units=300, \n            dropout=dropout_threshold, \n            return_sequences=True,\n            kernel_initializer=initializer\n        ),\n        name='bidirectional_lstm'\n    )(embedding)\n    bi_lstm_feature = MaxPool1D(name='maxpool1d_lstm')(bi_lstm_feature)\n    bi_lstm_feature = LayerNormalization(name='layernorm_lstm')(bi_lstm_feature)\n    \n    # Convolutional Path (CNN) - Now After LSTM\n    cnn_feature = Conv1D(\n        filters=128, \n        kernel_size=3, \n        padding='valid', \n        activation='relu',\n        name='conv1d'\n    )(bi_lstm_feature)  # Changed input from 'feature' to 'bi_lstm_feature'\n    cnn_feature = MaxPool1D(name='maxpool1d_cnn')(cnn_feature)\n    cnn_feature = Dropout(dropout_threshold, name='dropout_cnn')(cnn_feature)\n    cnn_feature = LayerNormalization(name='layernorm_cnn')(cnn_feature)\n    \n    # Self-Attention Layer\n    attention_output = MultiHeadAttention(\n        num_heads=12, \n        key_dim=32, \n        name='multihead_attention'\n    )(cnn_feature, cnn_feature)\n    attention_output = LayerNormalization(name='layernorm_attention')(attention_output)\n    attention_output = Dropout(dropout_threshold, name='dropout_attention')(attention_output)\n    \n    # Global Max Pooling\n    cnn_pooled = GlobalMaxPooling1D(name='globalmaxpool_cnn')(cnn_feature)         \n    attention_pooled = GlobalMaxPooling1D(name='globalmaxpool_attention')(attention_output)  \n\n    # Concatenate Features\n    combined = Concatenate(name='concatenate')([cnn_pooled, attention_pooled])\n    combined = LayerNormalization(name='layernorm_combined')(combined)\n    combined = Dropout(dropout_threshold, name='dropout_combined')(combined)  \n    \n    # Classification Layers\n    dense = Dense(256, activation='relu', name='dense_1')(combined)  \n    dense = Dropout(dropout_threshold, name='dropout_dense_1')(dense)\n    output = Dense(3, activation='sigmoid', name='output_layer')(dense)\n\n    # Define the Model\n    model = Model(inputs=input_layer, outputs=output, name='rearranged_model')\n    return model\n\n# Example usage:\n# data_vocab_size = 2155  # Replace with your actual vocab size\n# embedding_matrix = your_embedding_matrix  # Replace with your actual embedding matrix\nmodel = generate_model_1(data_vocab_size, embedding_matrix)\n\nadamw = AdamW(learning_rate=4e-4, weight_decay=0.0)\nmodel.compile(optimizer=adamw, loss='binary_crossentropy', metrics=['accuracy'])\nmodel.summary()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T03:49:37.798379Z","iopub.status.idle":"2025-01-29T03:49:37.798705Z","shell.execute_reply.started":"2025-01-29T03:49:37.798527Z","shell.execute_reply":"2025-01-29T03:49:37.798542Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import Input, Embedding, Conv1D, MaxPool1D, Dropout, LayerNormalization\nfrom tensorflow.keras.layers import Bidirectional, LSTM, GRU, Concatenate, GlobalMaxPooling1D, Dense, MultiHeadAttention, Attention\n\ndef generate_model_luong_attention(data_vocab_size):\n    dropout_threshold = 0.1\n    input_dim = data_vocab_size\n    output_dim = 300  \n    input_length = 256\n    initializer = tf.keras.initializers.GlorotNormal()\n\n    input_layer = Input(shape=(input_length,))\n    feature = Embedding(input_dim=input_dim, output_dim=output_dim, \n                        embeddings_initializer=initializer)(input_layer)\n\n    # Convolutional Path\n    cnn_feature = Conv1D(filters=128, kernel_size=3, padding='same', activation='relu')(feature)  # Increased filters\n    cnn_feature = MaxPool1D()(cnn_feature)  # Reduces to 128\n    cnn_feature = Dropout(dropout_threshold)(cnn_feature)\n    cnn_feature = Conv1D(filters=128, kernel_size=3, padding='same', activation='relu')(cnn_feature)  # Increased filters\n    cnn_feature = MaxPool1D()(cnn_feature)  # Reduces to 64\n    cnn_feature = LayerNormalization()(cnn_feature)\n    cnn_feature = Dropout(dropout_threshold)(cnn_feature)\n\n    # Recurrent Path\n    bi_lstm_feature = Bidirectional(LSTM(units=64, dropout=dropout_threshold, return_sequences=True,\n                                         kernel_initializer=initializer))(cnn_feature)  # Increased units\n    bi_lstm_feature = MaxPool1D()(bi_lstm_feature) \n    bi_lstm_feature = LayerNormalization()(bi_lstm_feature)\n\n    # Self-Attention Layer\n    attention_output = Attention(use_scale=True, score_mode='dot', dropout=0.1)([bi_lstm_feature, bi_lstm_feature]) #Luong-Style\n    attention_output = LayerNormalization()(attention_output)\n    attention_output = Dropout(dropout_threshold)(attention_output)\n\n    # Apply GlobalMaxPooling1D to both feature maps\n    cnn_pooled = GlobalMaxPooling1D()(cnn_feature)         \n    attention_pooled = GlobalMaxPooling1D()(attention_output)  \n\n    # Concatenate the pooled features\n    combine_feature = Concatenate()([cnn_pooled, attention_pooled])\n    combine_feature = LayerNormalization()(combine_feature)\n    combine_feature = Dropout(dropout_threshold)(combine_feature)  \n    \n    # Classification Layers\n    classifier = Dense(128, activation='relu')(combine_feature)  \n    classifier = Dropout(dropout_threshold)(classifier)\n    classifier = Dense(64, activation='relu')(classifier)  \n    classifier = Dropout(dropout_threshold)(classifier)\n    classifier = Dense(3, activation='softmax')(classifier)\n\n    model = tf.keras.Model(inputs=input_layer, outputs=classifier)\n    return model\n\n# Example usage:\nmodel = generate_model_luong_attention(data_vocab_size)\nadam = Adam(learning_rate=0.0001)\nmodel.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T03:49:37.799972Z","iopub.status.idle":"2025-01-29T03:49:37.800263Z","shell.execute_reply.started":"2025-01-29T03:49:37.800116Z","shell.execute_reply":"2025-01-29T03:49:37.800131Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import Input, Embedding, Conv1D, MaxPool1D, Dropout, LayerNormalization\nfrom tensorflow.keras.layers import Bidirectional, LSTM, GRU, Concatenate, GlobalMaxPooling1D, Dense, MultiHeadAttention\nfrom tensorflow.keras.optimizers import AdamW\n\ndef generate_model_querygroup_attention(data_vocab_size):\n    dropout_threshold = 0.3 \n    input_dim = data_vocab_size\n    output_dim = 100  \n    input_length = 150\n    initializer = tf.keras.initializers.LecunNormal()\n\n    input_layer = Input(shape=(input_length,))\n    feature = Embedding(input_dim=input_dim, output_dim=output_dim, \n                        embeddings_initializer=initializer)(input_layer)\n\n    # Convolutional Path\n    cnn_feature = Conv1D(filters=128, kernel_size=3, padding='same', activation='relu')(feature)  # Increased filters\n    cnn_feature = MaxPool1D()(cnn_feature)  # Reduces to 128\n    cnn_feature = Dropout(dropout_threshold)(cnn_feature)\n    cnn_feature = Conv1D(filters=128, kernel_size=3, padding='same', activation='relu')(cnn_feature)  # Increased filters\n    cnn_feature = MaxPool1D()(cnn_feature)  # Reduces to 64\n    cnn_feature = LayerNormalization()(cnn_feature)\n    cnn_feature = Dropout(dropout_threshold)(cnn_feature)\n\n        # Recurrent Path\n    bi_lstm_feature = Bidirectional(LSTM(units=64, dropout=dropout_threshold, return_sequences=True,\n                                         kernel_initializer=initializer))(cnn_feature)  # Increased units\n    bi_lstm_feature = MaxPool1D()(bi_lstm_feature) \n    bi_lstm_feature = LayerNormalization()(bi_lstm_feature)\n    \n\n    attention_layer = tf.keras.layers.GroupQueryAttention(\n        head_dim=64, \n        num_query_heads=8, \n        num_key_value_heads=8, \n        dropout=0.2\n    )\n    # Self-Attention Layer\n    attention_output = attention_layer(bi_lstm_feature, bi_lstm_feature) #Luong-Style\n    attention_output = LayerNormalization()(attention_output)\n    attention_output = Dropout(dropout_threshold)(attention_output)\n\n    # Apply GlobalMaxPooling1D to both feature maps\n    cnn_pooled = GlobalMaxPooling1D()(cnn_feature)         \n    attention_pooled = GlobalMaxPooling1D()(attention_output)  \n\n    # Concatenate the pooled features\n    combine_feature = Concatenate()([cnn_pooled, attention_pooled])\n    combine_feature = LayerNormalization()(combine_feature)\n    combine_feature = Dropout(dropout_threshold)(combine_feature)  \n    \n    # Classification Layers\n    classifier = Dense(128, activation='relu')(combine_feature)  \n    classifier = Dropout(dropout_threshold)(classifier)\n    classifier = Dense(64, activation='relu')(classifier)  \n    classifier = Dropout(dropout_threshold)(classifier)\n    classifier = Dense(3, activation='softmax')(classifier)\n\n    model = tf.keras.Model(inputs=input_layer, outputs=classifier)\n    return model\n\n# Example usage:\ndata_vocab_size = 3814  # Replace with your actual vocab size\nmodel = generate_model_querygroup_attention(data_vocab_size)\nadamw = AdamW(learning_rate=4e-4, weight_decay=0.01)\nmodel.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T03:49:37.801307Z","iopub.status.idle":"2025-01-29T03:49:37.801585Z","shell.execute_reply.started":"2025-01-29T03:49:37.801445Z","shell.execute_reply":"2025-01-29T03:49:37.801460Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# dot_img_file = 'model_visualize.png'\n# tf.keras.utils.plot_model(model, to_file=dot_img_file, show_shapes=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T03:49:37.802821Z","iopub.status.idle":"2025-01-29T03:49:37.803116Z","shell.execute_reply.started":"2025-01-29T03:49:37.802969Z","shell.execute_reply":"2025-01-29T03:49:37.802984Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Detect and init the TPU\n# tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n\n# # Instantiate a distribution strategy\n# strategy = tf.distribute.MirroredStrategy()\n\n# with strategy.scope():\n#     model = generate_model(data_vocab_size)\n#     model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n\n# early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n\n\n# history = model.fit(\n#     x=X_train,\n#     y=y_train,\n#     validation_data=(X_val, y_val),\n#     epochs=50,\n#     batch_size=32,\n#     callbacks=[early_stopping]\n# )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T03:49:37.804000Z","iopub.status.idle":"2025-01-29T03:49:37.804311Z","shell.execute_reply.started":"2025-01-29T03:49:37.804161Z","shell.execute_reply":"2025-01-29T03:49:37.804178Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Import necessary libraries\nfrom imblearn.under_sampling import (\n    ClusterCentroids,\n    CondensedNearestNeighbour,\n    RandomUnderSampler,\n    NearMiss,\n    EditedNearestNeighbours,\n    RepeatedEditedNearestNeighbours,\n    InstanceHardnessThreshold,\n    AllKNN,\n    NeighbourhoodCleaningRule,\n    OneSidedSelection,\n    TomekLinks\n)\nfrom imblearn.over_sampling import (\n    RandomOverSampler,\n    SMOTEN,\n    SMOTE,\n    SMOTENC,\n    ADASYN,\n    BorderlineSMOTE,\n    KMeansSMOTE,\n    SVMSMOTE\n)\nfrom imblearn.combine import (\n    SMOTEENN,\n    SMOTETomek\n)\n\n# Initialize Under-Sampling Methods\ncc = ClusterCentroids(\n    estimator=MiniBatchKMeans(n_init=1, random_state=2004), random_state=2004\n)\n\ncnn = CondensedNearestNeighbour(random_state=2004)  \n\nrus = RandomUnderSampler(random_state=2004)\n\nnearmiss = NearMiss()\n\nenn = EditedNearestNeighbours()\n\nrenn = RepeatedEditedNearestNeighbours()\n\niht = InstanceHardnessThreshold(random_state=2004)\n\nall_knn = AllKNN()\n\nncr = NeighbourhoodCleaningRule()\n\noss = OneSidedSelection(random_state=2004)\n\ntl = TomekLinks()\n\n# Initialize Over-Sampling Methods\nros = RandomOverSampler(random_state=1004)\n\nsmoten = SMOTEN(random_state=2004)\n\nsmote = SMOTE(sampling_strategy='auto', random_state=2004)\n\nsmotenc = SMOTENC(sampling_strategy='auto', random_state=2004, categorical_features=[...])  # Specify categorical feature indices\n\nadasyn = ADASYN(random_state=2004)\n\nsm = BorderlineSMOTE(random_state=2004)\n\nkmean_smote = KMeansSMOTE(\n    kmeans_estimator=MiniBatchKMeans(n_init=3, random_state=2004), random_state=2004\n)\n\nsvm_smote = SVMSMOTE(random_state=2004)\n\n# Initialize Combined Over and Under Sampling Methods\nsmoteen = SMOTEENN(random_state=2004)\n\nsmt = SMOTETomek(random_state=2004)\n\n# Apply Under-Sampling Methods\nX_resampled_cc, y_resampled_cc = cc.fit_resample(train_features, y_train)\nX_resampled_cnn, y_resampled_cnn = cnn.fit_resample(train_features, y_train)\nX_resampled_rus, y_resampled_rus = rus.fit_resample(train_features, y_train)\nX_resampled_nearmiss, y_resampled_nearmiss = nearmiss.fit_resample(train_features, y_train)\nX_resampled_enn, y_resampled_enn = enn.fit_resample(train_features, y_train)\nX_resampled_renn, y_resampled_renn = renn.fit_resample(train_features, y_train)\nX_resampled_iht, y_resampled_iht = iht.fit_resample(train_features, y_train)\nX_resampled_all_knn, y_resampled_all_knn = all_knn.fit_resample(train_features, y_train)\nX_resampled_ncr, y_resampled_ncr = ncr.fit_resample(train_features, y_train)\nX_resampled_oss, y_resampled_oss = oss.fit_resample(train_features, y_train)\nX_resampled_tl, y_resampled_tl = tl.fit_resample(train_features, y_train)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T03:49:37.805343Z","iopub.status.idle":"2025-01-29T03:49:37.805664Z","shell.execute_reply.started":"2025-01-29T03:49:37.805486Z","shell.execute_reply":"2025-01-29T03:49:37.805501Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Apply Over-Sampling Methods\nX_resampled_ros, y_resampled_ros = ros.fit_resample(train_features, y_train)\nX_resampled_smoten, y_resampled_smoten = smoten.fit_resample(train_features, y_train)\nX_resampled_smote, y_resampled_smote = smote.fit_resample(train_features, y_train)\n# Note: For SMOTENC, specify the indices of categorical features\n# Replace [...] with actual indices, e.g., [0, 2, 3]\n\nX_resampled_sm, y_resampled_sm = sm.fit_resample(train_features, y_train)\nX_resampled_svm_smote, y_resampled_svm_smote = svm_smote.fit_resample(train_features, y_train)\n\n# Apply Combined Over and Under Sampling Methods\nX_resampled_smoteen, y_resampled_smoteen = smoteen.fit_resample(train_features, y_train)\nX_resampled_smt, y_resampled_smt = smt.fit_resample(train_features, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T03:49:37.807102Z","iopub.status.idle":"2025-01-29T03:49:37.807411Z","shell.execute_reply.started":"2025-01-29T03:49:37.807260Z","shell.execute_reply":"2025-01-29T03:49:37.807277Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ros = RandomOverSampler(random_state=3001)\nX_resampled_ros, y_resampled_ros = ros.fit_resample(train_features, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T03:49:37.809361Z","iopub.status.idle":"2025-01-29T03:49:37.809715Z","shell.execute_reply.started":"2025-01-29T03:49:37.809525Z","shell.execute_reply":"2025-01-29T03:49:37.809541Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n\n# Define early stopping callback\nimport tensorflow as tf\n\nclass WarmUp(tf.keras.optimizers.schedules.LearningRateSchedule):\n    def __init__(self, initial_lr, warmup_steps, decay_steps):\n        super(WarmUp, self).__init__()\n        self.initial_lr = initial_lr\n        self.warmup_steps = warmup_steps\n        self.decay_steps = decay_steps\n\n    def __call__(self, step):\n        warmup_lr = self.initial_lr * (step / self.warmup_steps)\n        decay_lr = tf.keras.optimizers.schedules.ExponentialDecay(\n            initial_learning_rate=self.initial_lr,\n            decay_steps=self.decay_steps,\n            decay_rate=0.96\n        )(step - self.warmup_steps)\n        return tf.cond(step < self.warmup_steps, lambda: warmup_lr, lambda: decay_lr)\n\nlr_schedule = WarmUp(initial_lr=1e-4, warmup_steps=500, decay_steps=10000)\nadamw = AdamW(learning_rate=lr_schedule)\n\n\n# early_stopping = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n# history = model.fit(\n#     x=X_resampled_smote,\n#     y=y_resampled_smote,\n#     validation_data=(dev_features, y_dev),\n#     epochs=100,\n#     batch_size=128,\n#     callbacks=[early_stopping, warm_up]\n# )\n\n\nearly_stopping = EarlyStopping(monitor='val_accuracy', patience=20, restore_best_weights=True)\nhistory = model.fit(\n    x=train_features,\n    y=y_train,\n    validation_data=(dev_features, y_dev),\n    epochs=100,\n    batch_size=64,\n    callbacks=[early_stopping]\n)\n\n# early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n# history = model.fit(\n#     x=X_resampled_ros,\n#     y=y_resampled_ros,\n#     validation_data=(dev_features, y_dev),\n#     epochs=100,\n#     batch_size=128,\n#     callbacks=[early_stopping, warm_up]\n# )\n\n# history = model.fit(\n#     x=X_resampled_cc,\n#     y=y_resampled_cc,\n#     validation_data=(dev_features, y_dev),\n#     epochs=100,\n#     batch_size=128,\n#     callbacks=[early_stopping, warm_up]\n# )\n\n# early_stopping = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n\n# history = model.fit(\n#     x=X_resampled_cnn,\n#     y=y_resampled_cnn,\n#     validation_data=(dev_features, y_dev),\n#     epochs=100,\n#     batch_size=128,\n#     callbacks=[early_stopping, warm_up]\n# )\n\n# early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n# history = model.fit(\n#     x=X_resampled_rus,\n#     y=y_resampled_rus,\n#     validation_data=(dev_features, y_dev),\n#     epochs=100,\n#     batch_size=128,\n#     callbacks=[early_stopping, warm_up]\n# )\n\n# early_stopping = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n\n\n# early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n# history = model.fit(\n#     x=X_resampled_smoteen,\n#     y=y_resampled_smoteen,\n#     validation_data=(dev_features, y_dev),\n#     epochs=100,\n#     batch_size=128,\n#     callbacks=[early_stopping, warm_up]\n# )\n\n# history = model.fit(\n#     x=X_resampled_nearmiss,\n#     y=y_resampled_nearmiss,\n#     validation_data=(dev_features, y_dev),\n#     epochs=100,\n#     batch_size=128,\n#     callbacks=[early_stopping, warm_up]\n# )\n\n# early_stopping = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n\n\n# history = model.fit(\n#     x=X_resampled_enn,\n#     y=y_resampled_enn,\n#     validation_data=(dev_features, y_dev),\n#     epochs=100,\n#     batch_size=128,\n#     callbacks=[early_stopping, warm_up]\n# )\n\n# early_stopping = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n\n\n# history = model.fit(\n#     x=X_resampled_renn,\n#     y=y_resampled_renn,\n#     validation_data=(dev_features, y_dev),\n#     epochs=100,\n#     batch_size=128,\n#     callbacks=[early_stopping, warm_up]\n# )\n\n# early_stopping = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n\n# history = model.fit(\n#     x=X_resampled_iht,\n#     y=y_resampled_iht,\n#     validation_data=(dev_features, y_dev),\n#     epochs=100,\n#     batch_size=128,\n#     callbacks=[early_stopping, warm_up]\n# )\n\n# early_stopping = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n\n# history = model.fit(\n#     x=X_resampled_all_knn,\n#     y=y_resampled_all_knn,\n#     validation_data=(dev_features, y_dev),\n#     epochs=100,\n#     batch_size=128,\n#     callbacks=[early_stopping, warm_up]\n# )\n\n# early_stopping = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n\n# history = model.fit(\n#     x=X_resampled_ncr,\n#     y=y_resampled_ncr,\n#     validation_data=(dev_features, y_dev),\n#     epochs=100,\n#     batch_size=128,\n#     callbacks=[early_stopping, warm_up]\n# )\n\n# early_stopping = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n\n# history = model.fit(\n#     x=X_resampled_oss,\n#     y=y_resampled_oss,\n#     validation_data=(dev_features, y_dev),\n#     epochs=100,\n#     batch_size=128,\n#     callbacks=[early_stopping, warm_up]\n# )\n\n# early_stopping = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n\n# history = model.fit(\n#     x=X_resampled_tl,\n#     y=y_resampled_tl,\n#     validation_data=(dev_features, y_dev),\n#     epochs=100,\n#     batch_size=128,\n#     callbacks=[early_stopping, warm_up]\n# )\n\n# early_stopping = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n\n# history = model.fit(\n#     x=X_resampled_smoten,\n#     y=y_resampled_smoten,\n#     validation_data=(dev_features, y_dev),\n#     epochs=100,\n#     batch_size=128,\n#     callbacks=[early_stopping, warm_up]\n# )\n\n\n# early_stopping = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n\n# history = model.fit(\n#     x=X_resampled_sm,\n#     y=y_resampled_sm,\n#     validation_data=(dev_features, y_dev),\n#     epochs=100,\n#     batch_size=128,\n#     callbacks=[early_stopping, warm_up]\n# )\n\n# early_stopping = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n\n# history = model.fit(\n#     x=X_resampled_svm_smote,\n#     y=y_resampled_svm_smote,\n#     validation_data=(dev_features, y_dev),\n#     epochs=100,\n#     batch_size=128,\n#     callbacks=[early_stopping, warm_up]\n# )\n\n# early_stopping = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n\n\n\n# early_stopping = EarlyStoppiSequentialng(monitor='val_accuracy', patience=10, restore_best_weights=True)\n\n# history = model.fit(\n#     x=X_resampled_smt,\n#     y=y_resampled_smt,\n#     validation_data=(dev_features, y_dev),\n#     epochs=100,\n#     batch_size=128,\n#     callbacks=[early_stopping, warm_up]\n# )\n\n# early_stopping = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T03:49:37.811381Z","iopub.status.idle":"2025-01-29T03:49:37.811773Z","shell.execute_reply.started":"2025-01-29T03:49:37.811551Z","shell.execute_reply":"2025-01-29T03:49:37.811568Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.save('model_cnn_bilstm_multihead_attention_clean_edition.keras')\nmodel.load_weights(\"model_cnn_bilstm_multihead_attention_clean_edition.keras\")\nmodel.evaluate(test_features, y_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T03:49:37.813167Z","iopub.status.idle":"2025-01-29T03:49:37.813451Z","shell.execute_reply.started":"2025-01-29T03:49:37.813312Z","shell.execute_reply":"2025-01-29T03:49:37.813327Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nlabel_class = ['Tiêu cực', 'Trung Lập', 'Tích cực']\nmodel.load_weights('/kaggle/working/model_cnn_bilstm_multihead_attention_clean_edition.keras')\nmodel.evaluate(test_features, y_test)\n\npreds = model.predict(test_features)\npreds = tf.round(preds).numpy()\n\nprint(classification_report(y_test, preds, target_names=label_class, zero_division=0))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T03:49:37.814361Z","iopub.status.idle":"2025-01-29T03:49:37.814726Z","shell.execute_reply.started":"2025-01-29T03:49:37.814524Z","shell.execute_reply":"2025-01-29T03:49:37.814541Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nlabel_class = ['Tiêu cực', 'Trung Lập', 'Tích cực']\n\n\ny_test_single_label = np.argmax(y_test, axis=1)\npreds_single_label = np.argmax(preds, axis=1)\n\ncm = confusion_matrix(y_test_single_label, preds_single_label, labels=[0, 1, 2])\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_class)\ndisp.plot()\nplt.gca().grid(False)\nplt.title('Bi-LSTM With Multi Head Attention')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T03:49:37.815921Z","iopub.status.idle":"2025-01-29T03:49:37.816244Z","shell.execute_reply.started":"2025-01-29T03:49:37.816093Z","shell.execute_reply":"2025-01-29T03:49:37.816110Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import Input, Embedding, Conv1D, MaxPool1D, Dropout, LayerNormalization\nfrom tensorflow.keras.layers import Bidirectional, LSTM, GRU, SimpleRNN, Concatenate, GlobalMaxPooling1D, Dense\nfrom tensorflow.keras.optimizers import Adam\n\ndef generate_modelRNN(data_vocab_size):\n    dropout_threshold = 0.3  # Reduced dropout\n    input_dim = data_vocab_size\n    output_dim = 64  # Increased embedding dimension\n    input_length = 512\n    initializer = tf.keras.initializers.GlorotNormal()\n\n    input_layer = Input(shape=(input_length,))\n    feature = Embedding(input_dim=input_dim, output_dim=output_dim, input_length=input_length, \n                        embeddings_initializer=initializer)(input_layer)\n\n    # Convolutional Path\n    cnn_feature = Conv1D(filters=64, kernel_size=3, padding='same', activation='relu')(feature)  # Increased filters\n    cnn_feature = MaxPool1D()(cnn_feature)  # Reduces to 256\n    cnn_feature = Dropout(dropout_threshold)(cnn_feature)\n    cnn_feature = Conv1D(filters=64, kernel_size=3, padding='same', activation='relu')(cnn_feature)  # Increased filters\n    cnn_feature = MaxPool1D()(cnn_feature)  # Reduces to 128\n    cnn_feature = LayerNormalization()(cnn_feature)\n    cnn_feature = Dropout(dropout_threshold)(cnn_feature)\n\n    # Recurrent Path\n    bi_rnn_feature = Bidirectional(SimpleRNN(units=64, dropout=dropout_threshold, return_sequences=True,\n                                             kernel_initializer=initializer))(cnn_feature)  # Replaced LSTM with SimpleRNN\n    bi_rnn_feature = MaxPool1D()(bi_rnn_feature)  # Reduces to 64\n    bi_rnn_feature = LayerNormalization()(bi_rnn_feature)\n\n    # Apply GlobalMaxPooling1D to both feature maps\n    cnn_pooled = GlobalMaxPooling1D()(cnn_feature)          # (None, 64)\n    bi_rnn_pooled = GlobalMaxPooling1D()(bi_rnn_feature)    # (None, 128)\n\n    # Concatenate the pooled features\n    combine_feature = Concatenate()([cnn_pooled, bi_rnn_pooled])  # (None, 192)\n    combine_feature = LayerNormalization()(combine_feature)\n\n    # Classification Layers\n    classifier = Dense(128, activation='relu')(combine_feature)  # Increased units\n    classifier = Dropout(0.2)(classifier)\n    classifier = Dense(64, activation='relu')(classifier)  # Reduced units\n    classifier = Dropout(0.2)(classifier)\n    classifier = Dense(3, activation='softmax')(classifier)\n\n    model = tf.keras.Model(inputs=input_layer, outputs=classifier)\n    return model\n\n\ndata_vocab_size = 3814 \nmodelRNN = generate_modelRNN(data_vocab_size)\nadam = Adam(learning_rate=0.0001)\nmodelRNN.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\nmodelRNN.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T03:49:37.817387Z","iopub.status.idle":"2025-01-29T03:49:37.817744Z","shell.execute_reply.started":"2025-01-29T03:49:37.817547Z","shell.execute_reply":"2025-01-29T03:49:37.817564Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping\n\n# Define early stopping callback\nearly_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n\n# Train the model with early stopping\nhistory = modelRNN.fit(\n    x=train_features,\n    y=y_train,\n    validation_data=(dev_features, y_dev),\n    epochs=50,\n    batch_size=32,\n    callbacks=[early_stopping]\n)\n\n\nmodelRNN.save('model_cnn_biRnn.keras')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T03:49:37.819099Z","iopub.status.idle":"2025-01-29T03:49:37.819404Z","shell.execute_reply.started":"2025-01-29T03:49:37.819255Z","shell.execute_reply":"2025-01-29T03:49:37.819272Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"modelRNN.load_weights(\"model_cnn_biRnn.keras\")\nmodelRNN.evaluate(test_features, y_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T03:49:37.820435Z","iopub.status.idle":"2025-01-29T03:49:37.820771Z","shell.execute_reply.started":"2025-01-29T03:49:37.820580Z","shell.execute_reply":"2025-01-29T03:49:37.820595Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nlabel_class = ['Tiêu cực', 'Trung Lập', 'Tích cực']\nmodelRNN.load_weights('model_cnn_biRnn.keras')\nmodelRNN.evaluate(test_features, y_test)\n\npreds_RNN = modelRNN.predict(test_features)\npreds_RNN = tf.round(preds).numpy()\n\nprint(classification_report(y_test, preds_RNN, target_names=label_class, zero_division=0))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T03:49:37.821659Z","iopub.status.idle":"2025-01-29T03:49:37.821965Z","shell.execute_reply.started":"2025-01-29T03:49:37.821805Z","shell.execute_reply":"2025-01-29T03:49:37.821821Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nlabel_class = ['Tiêu cực', 'Trung Lập', 'Tích cực']\n\ny_test_single_label = np.argmax(y_test, axis=1)\npreds_single_label_RNN = np.argmax(preds_RNN, axis=1)\n\ncm = confusion_matrix(y_test_single_label, preds_single_label_RNN, labels=[0, 1, 2])\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_class)\ndisp.plot()\nplt.gca().grid(False)\nplt.title('Bi-RNN')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T03:49:37.822814Z","iopub.status.idle":"2025-01-29T03:49:37.823108Z","shell.execute_reply.started":"2025-01-29T03:49:37.822960Z","shell.execute_reply":"2025-01-29T03:49:37.822976Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def preprocess_raw_input(raw_input, tokenizer):\n    input_text_pre = list(tf.keras.preprocessing.text.text_to_word_sequence(raw_input))\n    input_text_pre = \" \".join(input_text_pre)\n    input_text_pre_accent = ViTokenizer.tokenize(input_text_pre)\n    print(\"Text preprocessed:\", input_text_pre_accent)\n    tokenized_data_text = tokenizer.texts_to_sequences([input_text_pre_accent])\n    vec_data = pad_sequences(tokenized_data_text, padding='post', maxlen=512)\n    return vec_data\n\ndef inference_model(input_feature, model):\n    output = model(input_feature).numpy()[0]\n    result = output.argmax()\n    conf = float(output.max())\n    label_dict = {'Tiêu cực': 0, 'Trung lập': 1, 'Tích cực': 2}\n    label = list(label_dict.keys())\n    return label[int(result)], conf\n\ndef prediction(raw_input, tokenizer, model):\n    input_model = preprocess_raw_input(raw_input, tokenizer)\n    result, conf = inference_model(input_model, model)\n    return result, conf\n\nmy_model = generate_model(data_vocab_size)\nmy_model.load_weights(\"/kaggle/working/model_cnn_bilstm.keras\")\n\nwith open(\"tokenizer_data.pkl\", \"rb\") as input_file:\n    my_tokenizer = pickle.load(input_file)\n\nprint(prediction(\"Cô dạy rất tốt\", my_tokenizer, my_model))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T03:49:37.824052Z","iopub.status.idle":"2025-01-29T03:49:37.824336Z","shell.execute_reply.started":"2025-01-29T03:49:37.824193Z","shell.execute_reply":"2025-01-29T03:49:37.824208Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}