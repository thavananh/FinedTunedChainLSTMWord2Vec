Model Parameters:
learning_rate: 0.0008944020651975486
batch_size: 128
dropout_features: 0.4
dropout_combine: 0.1
cnn_1_filter_size: 96
cnn_1_kernel_size: 3
cnn_1_padding: same
cnn_1_activation: sigmoid
cnn_1_dropout_rate: 0.2
cnn_2_filter_size: 64
cnn_2_kernel_size: 7
cnn_2_padding: same
cnn_2_activation: sigmoid
cnn_2_dropout_rate: 0.0
cnn_3_filter_size: 128
cnn_3_kernel_size: 5
cnn_3_padding: same
cnn_3_activation: relu
cnn_3_dropout_rate: 0.2
cnn_4_filter_size: 128
cnn_4_kernel_size: 7
cnn_4_padding: same
cnn_4_activation: tanh
cnn_4_dropout_rate: 0.0
lstm_1_units: 192
lstm_1_dropout_rate: 0.1
lstm_2_units: 448
lstm_2_dropout_rate: 0.1
multi_head_attention_num_heads: 8
multi_head_attention_key_dim: 128
multi_head_attention_dropout_rate: 0.30000000000000004
dense_1_units: 256
dense_1_dropout_rate: 0.1
dense_1_activation: relu
dense_2_units: 512
dense_2_dropout_rate: 0.4
dense_2_activation: silu
dense_3_units: 256
dense_3_dropout_rate: 0.30000000000000004
dense_3_activation: log_softmax

Word2Vec Parameters:
w2v_sg: 0
w2v_vector_size: 100
w2v_window: 3
w2v_min_count: 5
w2v_negative: 10
w2v_sample: 0.0008557709585340779

Classification Report:
              precision    recall  f1-score   support

    Negative      0.922     0.952     0.936       705
     Neutral      0.575     0.315     0.407        73
    Positive      0.939     0.950     0.944       805

    accuracy                          0.922      1583
   macro avg      0.812     0.739     0.763      1583
weighted avg      0.914     0.922     0.916      1583

Confusion Matrix:
    Negative  Neutral  Positive
Negative   671      13      21
Neutral    21      23      29
Positive   36      4      765
