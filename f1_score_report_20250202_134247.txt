Model Parameters:
learning_rate: 0.00015370018284830984
batch_size: 32
dropout_features: 0.2
dropout_combine: 0.1
cnn_1_filter_size: 192
cnn_1_kernel_size: 2
cnn_1_padding: same
cnn_1_activation: silu
cnn_1_dropout_rate: 0.2
cnn_2_filter_size: 64
cnn_2_kernel_size: 3
cnn_2_padding: valid
cnn_2_activation: gelu
cnn_2_dropout_rate: 0.2
cnn_3_filter_size: 224
cnn_3_kernel_size: 2
cnn_3_padding: valid
cnn_3_activation: gelu
cnn_3_dropout_rate: 0.2
cnn_4_filter_size: 64
cnn_4_kernel_size: 2
cnn_4_padding: same
cnn_4_activation: gelu
cnn_4_dropout_rate: 0.2
lstm_1_units: 64
lstm_1_dropout_rate: 0.1
lstm_2_units: 64
lstm_2_dropout_rate: 0.0
multi_head_attention_num_heads: 4
multi_head_attention_key_dim: 96
multi_head_attention_dropout_rate: 0.30000000000000004
dense_1_units: 384
dense_1_dropout_rate: 0.30000000000000004
dense_1_activation: elu
dense_2_units: 384
dense_2_dropout_rate: 0.1
dense_2_activation: gelu
dense_3_units: 512
dense_3_dropout_rate: 0.2
dense_3_activation: log_softmax

Word2Vec Parameters:
w2v_sg: 1
w2v_vector_size: 300
w2v_window: 5
w2v_min_count: 6
w2v_negative: 5
w2v_sample: 2.324147117573731e-05
