Model Parameters:
learning_rate: 0.00026924762026542867
batch_size: 64
dropout_features: 0.30000000000000004
dropout_combine: 0.2
cnn_1_filter_size: 160
cnn_1_kernel_size: 1
cnn_1_padding: same
cnn_1_activation: silu
cnn_1_dropout_rate: 0.30000000000000004
cnn_2_filter_size: 64
cnn_2_kernel_size: 3
cnn_2_padding: same
cnn_2_activation: silu
cnn_2_dropout_rate: 0.30000000000000004
cnn_3_filter_size: 32
cnn_3_kernel_size: 1
cnn_3_padding: same
cnn_3_activation: silu
cnn_3_dropout_rate: 0.0
cnn_4_filter_size: 224
cnn_4_kernel_size: 1
cnn_4_padding: same
cnn_4_activation: silu
cnn_4_dropout_rate: 0.0
lstm_1_units: 320
lstm_1_dropout_rate: 0.4
lstm_2_units: 256
lstm_2_dropout_rate: 0.1
multi_head_attention_num_heads: 12
multi_head_attention_key_dim: 32
multi_head_attention_dropout_rate: 0.1
dense_1_units: 320
dense_1_dropout_rate: 0.0
dense_1_activation: silu
dense_2_units: 384
dense_2_dropout_rate: 0.0
dense_2_activation: silu
dense_3_units: 64
dense_3_dropout_rate: 0.1
dense_3_activation: softmax

Word2Vec Parameters:
w2v_sg: 1
w2v_vector_size: 300
w2v_window: 9
w2v_min_count: 16
w2v_negative: 10
w2v_sample: 3.0125351686553405e-05
