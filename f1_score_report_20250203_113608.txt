Model Parameters:
learning_rate: 0.00018176782369462325
batch_size: 128
dropout_features: 0.2
dropout_combine: 0.0
cnn_1_filter_size: 224
cnn_1_kernel_size: 3
cnn_1_padding: same
cnn_1_activation: silu
cnn_1_dropout_rate: 0.4
cnn_2_filter_size: 224
cnn_2_kernel_size: 2
cnn_2_padding: valid
cnn_2_activation: silu
cnn_2_dropout_rate: 0.30000000000000004
cnn_3_filter_size: 32
cnn_3_kernel_size: 1
cnn_3_padding: valid
cnn_3_activation: silu
cnn_3_dropout_rate: 0.1
cnn_4_filter_size: 64
cnn_4_kernel_size: 3
cnn_4_padding: valid
cnn_4_activation: silu
cnn_4_dropout_rate: 0.2
lstm_1_units: 320
lstm_1_dropout_rate: 0.4
lstm_2_units: 192
lstm_2_dropout_rate: 0.4
multi_head_attention_num_heads: 16
multi_head_attention_key_dim: 96
multi_head_attention_dropout_rate: 0.1
dense_1_units: 448
dense_1_dropout_rate: 0.4
dense_1_activation: silu
dense_2_units: 320
dense_2_dropout_rate: 0.30000000000000004
dense_2_activation: silu
dense_3_units: 128
dense_3_dropout_rate: 0.30000000000000004
dense_3_activation: softmax

Word2Vec Parameters:
w2v_sg: 1
w2v_vector_size: 100
w2v_window: 7
w2v_min_count: 16
w2v_negative: 15
w2v_sample: 0.0007354966228502024

Classification Report:
              precision    recall  f1-score   support

    Negative     0.9036    0.9574    0.9298       705
     Neutral     0.5957    0.3836    0.4667        73
    Positive     0.9493    0.9304    0.9398       805

    accuracy                         0.9172      1583
   macro avg     0.8162    0.7571    0.7787      1583
weighted avg     0.9127    0.9172    0.9135      1583

Confusion Matrix On Validation Set:
    Negative  Neutral  Positive
Negative   675      7      23
Neutral    28      28      17
Positive   44      12      749

Classification Report On Validatation Set:
              precision    recall  f1-score   support

    Negative     0.9036    0.9574    0.9298       705
     Neutral     0.5957    0.3836    0.4667        73
    Positive     0.9493    0.9304    0.9398       805

    accuracy                         0.9172      1583
   macro avg     0.8162    0.7571    0.7787      1583
weighted avg     0.9127    0.9172    0.9135      1583

Classification Report On Test Set:
              precision    recall  f1-score   support

    Negative     0.8772    0.9475    0.9110      1410
     Neutral     0.4900    0.2934    0.3670       167
    Positive     0.9307    0.9037    0.9170      1589

    accuracy                         0.8910      3166
   macro avg     0.7660    0.7149    0.7317      3166
weighted avg     0.8836    0.8910    0.8853      3166

Confusion Matrix On Validatation Set:
Confusion Matrix On Validation Set:
    Negative  Neutral  Positive
Negative   675      7      23
Neutral    28      28      17
Positive   44      12      749

Confusion Matrix On Validatation Set:
Confusion Matrix On Test Set:
    Negative  Neutral  Positive
Negative   1336      22      52
Neutral    63      49      55
Positive   124      29      1436
