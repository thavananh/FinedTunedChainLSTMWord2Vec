Model Parameters:
learning_rate: 0.0003401869192259701
batch_size: 32
dropout_features: 0.1
dropout_combine: 0.30000000000000004
cnn_1_filter_size: 160
cnn_1_kernel_size: 7
cnn_1_padding: valid
cnn_1_activation: relu
cnn_1_dropout_rate: 0.0
cnn_2_filter_size: 192
cnn_2_kernel_size: 7
cnn_2_padding: same
cnn_2_activation: relu
cnn_2_dropout_rate: 0.0
cnn_3_filter_size: 224
cnn_3_kernel_size: 5
cnn_3_padding: same
cnn_3_activation: sigmoid
cnn_3_dropout_rate: 0.1
cnn_4_filter_size: 256
cnn_4_kernel_size: 3
cnn_4_padding: valid
cnn_4_activation: tanh
cnn_4_dropout_rate: 0.1
lstm_1_units: 64
lstm_1_dropout_rate: 0.4
lstm_2_units: 256
lstm_2_dropout_rate: 0.0
multi_head_attention_num_heads: 8
multi_head_attention_key_dim: 32
multi_head_attention_dropout_rate: 0.0
dense_1_units: 512
dense_1_dropout_rate: 0.2
dense_1_activation: elu
dense_2_units: 384
dense_2_dropout_rate: 0.0
dense_2_activation: silu
dense_3_units: 128
dense_3_dropout_rate: 0.30000000000000004
dense_3_activation: softmax

Word2Vec Parameters:
w2v_sg: 1
w2v_vector_size: 300
w2v_window: 3
w2v_min_count: 5
w2v_negative: 5
w2v_sample: 0.00029337451866963583
